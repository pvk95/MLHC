{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment prediction\n",
    "## UCI Drug Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "import multiprocessing as mp\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_train = pd.read_csv(\n",
    "    './project2_data/drugsCom_raw/drugsComTrain_raw.tsv', delimiter='\\t', encoding='utf-8')\n",
    "df_test = pd.read_csv(\n",
    "    './project2_data/drugsCom_raw/drugsComTest_raw.tsv', delimiter='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "#Word Cloud\n",
    "%matplotlib inline\n",
    "pos_tweets = df_train[df_train.rating >= 5]\n",
    "pos_string = []\n",
    "for t in pos_tweets.review:\n",
    "    pos_string.append(t)\n",
    "pos_string = pd.Series(pos_string).str.cat(sep=' ')\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(pos_string)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.title('Positive reviews')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "neg_tweets = df_train[df_train.rating < 5]\n",
    "neg_string = []\n",
    "for t in neg_tweets.review:\n",
    "    neg_string.append(t)\n",
    "neg_string = pd.Series(neg_string).str.cat(sep=' ')\n",
    "\n",
    "wordcloud = WordCloud(width=1600, height=800, max_font_size=200).generate(neg_string)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.title('Negative reviews')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre process the comments and generate word2vec embeddings\n",
    "# process_chunk for converting a given comment into a word embedding for later use\n",
    "def process_chunk(comments):\n",
    "    processed_comments = []\n",
    "    lookup = {}\n",
    "    for comment in comments:\n",
    "        idxs = []\n",
    "        for i, word in enumerate(comment.split(' ')):\n",
    "            # if the comment is longer than the max-seq-length break the  loop\n",
    "            if i > max_seq_length:\n",
    "                break\n",
    "\n",
    "            # put everything into lowercase\n",
    "            word = word.lower()\n",
    "\n",
    "            # if empty word skip\n",
    "            if word == '':\n",
    "                continue\n",
    "            # if word is in our lookup table\n",
    "            if word in lookup.keys():\n",
    "                idx = lookup[word]\n",
    "            else:\n",
    "                try:\n",
    "                    idx = glove_word[glove_word == word].index[0]\n",
    "                except IndexError:\n",
    "                    idx = vocab_size\n",
    "                # put word into lookup table\n",
    "                lookup[word] = idx\n",
    "            idxs.append(idx)\n",
    "        processed_comments.append(idxs)\n",
    "\n",
    "    processed_comments = keras.preprocessing.sequence.pad_sequences(\n",
    "        processed_comments,\n",
    "        maxlen=max_seq_length,\n",
    "        padding='post',\n",
    "        truncating='post',\n",
    "        value=0\n",
    "    )\n",
    "    return processed_comments\n",
    "\n",
    "# Pre process the dataset; Remove punctuation marks etc. \n",
    "def process_comments(comments):\n",
    "    pre_comments = []\n",
    "    for comment in comments:\n",
    "        comment = comment.replace(',', '')\n",
    "        comment = comment.replace('.', '')\n",
    "        comment = comment.replace('(', '')\n",
    "        comment = comment.replace(')', '')\n",
    "        comment = comment.replace('\"', '')\n",
    "        comment = comment.replace('&amp;', 'and')\n",
    "        comment = comment.replace('!', '')\n",
    "        comment = comment.replace('/', ' ')\n",
    "        comment = comment.replace('&quot;', ' ')\n",
    "        comment = comment.replace('&#39;', ' ')\n",
    "        comment = comment.replace('\\n', ' ')\n",
    "        comment = comment.replace('\\r', ' ')\n",
    "        pre_comments.append(comment)\n",
    "    return np.array(pre_comments)\n",
    "\n",
    "# Parallelize the word embedding process \n",
    "def comments_to_idxs(comments):\n",
    "    cores = mp.cpu_count()\n",
    "    pool = mp.Pool(cores)\n",
    "    chunks = np.array_split(comments, cores)\n",
    "    results = pool.map(process_chunk, chunks)\n",
    "    results = np.vstack(results)\n",
    "    return results\n",
    "\n",
    "# The tf-idf features are extracted as a first resort for the model\n",
    "def getCommentFeatures(review,df,n_features=1000):\n",
    "    tvec = TfidfVectorizer(max_features=n_features)\n",
    "    X = tvec.fit_transform(review).todense().A\n",
    "    return [X,tvec]\n",
    "\n",
    "# Discretize the ratings into three classes as specified\n",
    "def getDiscreteLabels(ratings):\n",
    "    temp_ratings = ratings.copy()\n",
    "    for i, curr_rating in enumerate(ratings):\n",
    "        if (curr_rating >= 7):\n",
    "            temp_ratings[i] = 1\n",
    "        elif (curr_rating >= 4):\n",
    "            temp_ratings[i] = 0\n",
    "        else:\n",
    "            temp_ratings[i] = -1\n",
    "\n",
    "    return temp_ratings\n",
    "\n",
    "#Training performed on undersampled data: \n",
    "#Specifically undersample the positive class becuase it is at least 4 times as big \n",
    "def undersample_data(y_in):\n",
    "\n",
    "    np.random.seed(0)\n",
    "    n_samples = y_in.shape[0]\n",
    "    idxs_inclusion = [False]*n_samples\n",
    "    for i in range(n_samples):\n",
    "        if(y_in[i] == 1):\n",
    "            if(np.random.choice(np.arange(5),size=1)==0):\n",
    "                idxs_inclusion[i] = True\n",
    "        else:\n",
    "            idxs_inclusion[i] = True\n",
    "\n",
    "    return np.array(idxs_inclusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_train = process_comments(df_train.review.values)\n",
    "review_test = process_comments(df_test.review.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersample the data\n",
    "We first undersampled the data. Specifically the positive class is under sampled to imrpove trainng times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X,tvec] = getCommentFeatures(review_train,df_train,n_features=1000) # Entire training data\n",
    "y = getDiscreteLabels(ratings = df_train['rating'].values) # Entire test data\n",
    "\n",
    "X_test_data = tvec.transform(review_test)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0) # Split for validation\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(y_train,align = 'mid')\n",
    "plt.title('Class distribution before undersampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersample the training data\n",
    "idxs_inclusion = undersample_data(y_train)\n",
    "X_train = X_train[idxs_inclusion,:]\n",
    "y_train = y_train[idxs_inclusion]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.hist(y_train,align = 'mid')\n",
    "plt.title('Class distribution after undersampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different models as a baseline approach \n",
    "We tried the RandomForests and Adaboost methods as part of ensemble methods. \n",
    "We also used naive bayes and logistic regression models. \n",
    "SVM was not used in the inteerst of training times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(model, model_name, metrics):\n",
    "    print(\"Model: \", model_name)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    metrics = metrics.append({\"Name\": model_name, \"F1_score\": f1, \"Accuracy\": acc}, ignore_index=True)\n",
    "\n",
    "    return [y_pred, metrics]\n",
    "\n",
    "metrics = pd.DataFrame(data=[], columns=[\"Name\", \"F1_score\", \"Accuracy\"])\n",
    "\n",
    "rfc = RandomForestClassifier(class_weight='balanced', n_estimators=50)\n",
    "lg = LogisticRegression(class_weight='balanced')\n",
    "adb = ensemble.AdaBoostClassifier()\n",
    "cb = naive_bayes.ComplementNB()\n",
    "\n",
    "model_names = [\"RandomForest\", \"LogisticRegression\", \"Adaboost\", \"ComplementNB\"]\n",
    "models = [rfc, lg, adb, cb]\n",
    "\n",
    "all_models = zip(models, model_names)\n",
    "for model, model_name in all_models:\n",
    "    _, metrics = getScores(model, model_name, metrics)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from os import environ as cuda_environment\n",
    "\n",
    "cuda_environment[\"CUDA_VISIBLE_DEVICES\"] = str(0)\n",
    "\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=input_shape, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])\n",
    "\n",
    "def getCategorical(y):\n",
    "    n_samples = y.shape[0]\n",
    "    y_one_hot = np.zeros((n_samples, 3))\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i] == 1):\n",
    "            y_one_hot[i, 0] = 1\n",
    "        elif (y[i] == 0):\n",
    "            y_one_hot[i, 1] = 1\n",
    "        else:\n",
    "            y_one_hot[i, 2] = 1\n",
    "\n",
    "    return y_one_hot\n",
    "\n",
    "def flatten(y_to_flatten):\n",
    "    ytemp = np.argmax(y_to_flatten, axis=1)\n",
    "    y_pred_fl = ytemp.copy()\n",
    "    y_pred_fl[ytemp == 2] = -1\n",
    "    y_pred_fl[ytemp == 0] = 1\n",
    "    y_pred_fl[ytemp == 1] = 0\n",
    "\n",
    "    return y_pred_fl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_y_train = getCategorical(y_train)\n",
    "cat_y_test = getCategorical(y_test)\n",
    "\n",
    "history = model.fit(X_train, cat_y_train, epochs=10, validation_data=(X_test, cat_y_test))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "cat_y_pred = model.predict(X_test)\n",
    "y_pred = flatten(cat_y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "metrics = metrics.append({\"Name\": \"ANN\", \"F1_score\": f1, \"Accuracy\": acc}, ignore_index=True)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "# ! mkdir -p project2_data/glove\n",
    "# ! unzip -d project2_data/glove/ glove.twitter.27B.zip\n",
    "vocab_size = 10000\n",
    "vector_length = 25\n",
    "max_seq_length = 500\n",
    "glove_embeddings = pd.read_csv('project2_data/glove/glove.twitter.27B.25d.txt',\n",
    "                               header=None, delimiter=' ', encoding='utf-8', quoting=csv.QUOTE_NONE)\n",
    "print('Loaded glove embeddings')\n",
    "glove_embeddings = glove_embeddings[:vocab_size]\n",
    "\n",
    "glove_word = glove_embeddings[0]\n",
    "\n",
    "glove_vectors = glove_embeddings.iloc[:, 1:].values\n",
    "M1 = np.zeros((vocab_size + 1, vector_length + 1))\n",
    "M1[:-1, :-1] = glove_vectors\n",
    "glove_vectors = M1\n",
    "glove_vectors[-1, -1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Drug-Names appear multiple time in a non-unique fashion.\n",
    "# e.g. \"Stalevo\", \"Stalevo 200\"\n",
    "drug_names_raw = df_train.drugName.unique()\n",
    "\n",
    "for idx,drug in enumerate(drug_names_raw):\n",
    "    drug = drug.lower()\n",
    "    drug_names_raw[idx] = drug\n",
    "\n",
    "drug_names = np.copy(drug_names_raw)\n",
    "for idx1, drug1 in enumerate(drug_names_raw):\n",
    "    for idx2, drug2 in enumerate(drug_names_raw):\n",
    "        if drug1 in drug2 and drug1 != drug2 and drug2 in drug_names:\n",
    "            idx_ = np.where(drug_names == drug2)\n",
    "            drug_names = np.delete(drug_names, idx_)\n",
    "\n",
    "print(f'Deleted {len(drug_names_raw) - len(drug_names)} duplicate drug_names')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#Martin code\n",
    "# Find the mean rating of all drugs:\n",
    "# Split \n",
    "df_train_model, df_valid = train_test_split(df_train, random_state=42)\n",
    "\n",
    "mean_rating = np.mean(df_train_model.rating)\n",
    "\n",
    "# Find mean Rating for each Drugname\n",
    "drug_ratings = {}\n",
    "for drug_name in drug_names:\n",
    "    idxs = [drug_name in name for name in df_train_model.drugName.values]\n",
    "    ratings = df_train_model.rating[idxs]\n",
    "    mean_rating = np.mean(ratings)\n",
    "    drug_ratings[drug_name] = mean_rating\n",
    "print('Found the mean ratings for each drug')\n",
    "\n",
    "# Find ratings for df_valid\n",
    "valid_ratings = []\n",
    "num_not_found = 0\n",
    "for valid_drug in df_valid.drugName:\n",
    "    ratings = []\n",
    "    # The drug listing could contain multiple drugs\n",
    "    # e.g. 'drug A, drug B'\n",
    "    # we take the average rating of each drug\n",
    "    for key in drug_ratings.keys():\n",
    "        if key in valid_drug:\n",
    "            ratings.append(drug_ratings[key])\n",
    "\n",
    "    # If no drug with that name is found then the rating is set to the mean rating\n",
    "    if ratings == []:\n",
    "        ratings.append(mean_rating)\n",
    "        num_not_found += 1\n",
    "    rating = np.mean(ratings)\n",
    "    valid_ratings.append(rating)\n",
    "print(f'Number of not found drugs {num_not_found}')\n",
    "print(f'MSE: {mean_squared_error(df_valid.rating.values, valid_ratings)}')\n",
    "\n",
    "def to_labels(ratings):\n",
    "    labels = []\n",
    "    for rating in ratings:\n",
    "        if rating > 7:\n",
    "            label = 0\n",
    "        elif rating < 4:\n",
    "            label = 2\n",
    "        else:\n",
    "            label = 1\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "valid_true_labels = to_labels(df_valid.rating.values)\n",
    "valid_pred_labels = to_labels(valid_ratings)\n",
    "print(f'Accuracy: {accuracy_score(valid_true_labels, valid_pred_labels):.3} - f1: {f1_score(valid_true_labels, valid_pred_labels, average=\"micro\"):.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "\n",
    "train_idxs = process_chunk(review_train)\n",
    "test_idxs = process_chunk(review_test)\n",
    "\n",
    "np.save('project2_data/glove/train_idxs.npy', train_idxs)\n",
    "np.save('project2_data/glove/test_idxs.npy', test_idxs)\n",
    "\n",
    "#train_idxs = np.load('project2_data/glove/train_idxs.npy')\n",
    "#test_idxs = np.load('project2_data/glove/test_idxs.npy')\n",
    "\n",
    "max_seq_length = 50\n",
    "train_idxs = train_idxs[:, :max_seq_length] # Entire training data\n",
    "test_idxs = test_idxs[:, :max_seq_length] # Entire test data \n",
    "\n",
    "train_idx, valid_idx, train_y, valid_y = train_test_split(\n",
    "    train_idxs, df_train.rating.values, random_state=42)\n",
    "train_y_cat = pd.get_dummies(getDiscreteLabels(train_y)).values\n",
    "valid_y_cat = pd.get_dummies(getDiscreteLabels(valid_y)).values\n",
    "\n",
    "# Bidiretional LSTM\n",
    "\n",
    "batch_size = 64\n",
    "hidden_units = 256\n",
    "epochs = 20\n",
    "\n",
    "sequence_input = keras.layers.Input(shape=(max_seq_length,))\n",
    "embedding_sequence = keras.layers.Embedding(\n",
    "    vocab_size + 1,\n",
    "    vector_length + 1,\n",
    "    weights=[glove_vectors],\n",
    "    input_length=max_seq_length,\n",
    "    trainable=False\n",
    ")(sequence_input)\n",
    "\n",
    "lstm = keras.layers.Bidirectional(\n",
    "    keras.layers.LSTM(hidden_units))(embedding_sequence)\n",
    "drop = keras.layers.Dropout(0.5)(lstm)\n",
    "dense = keras.layers.Dense(128)(drop)\n",
    "out = keras.layers.Dense(3, activation='softmax')(dense)\n",
    "model = keras.models.Model(inputs=sequence_input, outputs=out)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = train_idx,y = train_y_cat,validation_data=(valid_idx, valid_y_cat),epochs=epochs)\n",
    "\n",
    "model.save('model_cat.h5')\n",
    "\n",
    "\n",
    "#model = keras.models.load_model('model_cat.h5')\n",
    "#print('loaded model')\n",
    "\n",
    "lstm_predictions = model.predict(valid_idx)\n",
    "print(f'ROC AUC {roc_auc_score(valid_y_cat, lstm_predictions):.3}  Acc: {accuracy_score(np.argmax(valid_y_cat, axis=1), np.argmax(lstm_predictions, axis=1)):.3} ')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "combined = np.hstack([pd.get_dummies(to_labels(valid_ratings)).values, lstm_predictions])\n",
    "\n",
    "train_combined, valid_combined, train_cat, valid_cat = train_test_split(combined, np.argmax(valid_y_cat, axis=1))\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(train_combined, train_cat)\n",
    "print(clf.score(valid_combined, valid_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
