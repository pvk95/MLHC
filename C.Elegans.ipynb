{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Elegans DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the C.Elegens .csv file. We add our own headers - labels stands for whether there is a splice site or not and the DNA is a string representing the DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('exercise_data/C_elegans_acc_seq.csv', header=None, names=['labels', 'DNA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the Test-Train-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(28)\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Make a copy of the raw dna sequences for later use with Shogun\n",
    "train_raw = np.array(train)\n",
    "test_raw = np.array(test)\n",
    "X_train = train_raw[:,1]\n",
    "y_train = train_raw[:,0]\n",
    "X_test = test_raw[:,1]\n",
    "y_test = test_raw[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.090909090909092\n",
      "8.977272727272727\n",
      "9.545454545454545\n"
     ]
    }
   ],
   "source": [
    "# Check the label proportions are similar. stratify=True for splitting threw a weird exception\n",
    "print(100*np.sum(df['labels']==1)/df.shape[0])\n",
    "print(100*np.sum(train['labels']==1)/train.shape[0])\n",
    "print(100*np.sum(test['labels']==1)/test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping DNA to a vector\n",
    "\n",
    "We will map the DNA into a vector, by mapping each Character (A,T,C,G) into a one-hot vector and then concatenating all these vectors together. As we have a string of 82 Characters this gives us a final vector of length 328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import utility\n",
    "train['DNA'] = train['DNA'].map(utility.map_dna_into_vector)\n",
    "test['DNA'] = test['DNA'].map(utility.map_dna_into_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DataFrame for later Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_eval_df = pd.DataFrame(data=[], columns=['Name', 'AUROC_cv', 'f1_cv', 'AUROC_test', 'AUPRC_test', 'f1_test'])\n",
    "auroc_eval_df = pd.DataFrame(data=[], columns=['Name', 'AUROC_cv', 'f1_cv', 'AUROC_test', 'AUPRC_test', 'f1_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, params, df, train, test, metric, half=0):\n",
    "    # Put Data into a readable Matrix format\n",
    "    train_data = np.vstack(train['DNA'].values)\n",
    "    test_data  = np.vstack(test['DNA'].values)\n",
    "    \n",
    "    if half:\n",
    "        if half == 1:\n",
    "            train_data = train_data[:, :int(train_data.shape[1]/2) - 4]\n",
    "            test_data = test_data[:, :int(test_data.shape[1]/2) - 4]\n",
    "        elif half == 2:\n",
    "            train_data = train_data[:, (int(train_data.shape[1]/2) + 8):]\n",
    "            test_data = test_data[:, (int(test_data.shape[1]/2) + 8):]\n",
    "        else:\n",
    "            raise ValueError('half must take values 0|1|2')\n",
    "    \n",
    "    # Create Instance of our Model\n",
    "    m = model()\n",
    "    \n",
    "    # Specify metrics\n",
    "    scoring = {'roc_auc': 'roc_auc', 'f1': 'f1'}\n",
    "    \n",
    "    # Search for the best params in our model and print the best score\n",
    "    clf = GridSearchCV(m, params, scoring=scoring, refit=metric, cv=5, n_jobs=-1)\n",
    "    clf.fit(train_data, train['labels'].values)\n",
    "    print(f\"The best score was: {clf.best_score_}\")\n",
    "    \n",
    "    # Extract cv metric results\n",
    "    results = clf.cv_results_\n",
    "    cv_dict = {'AUROC_cv':results['mean_test_roc_auc'][clf.best_index_],\n",
    "               'f1_cv':results['mean_test_f1'][clf.best_index_]}\n",
    "    \n",
    "    # Train our best model on the whole train-dataset\n",
    "    best_estimator = model(**clf.best_params_)\n",
    "    best_estimator.fit(train_data, train['labels'].values)\n",
    "    \n",
    "    # Evaluate on the Test set\n",
    "    pred_val = best_estimator.predict(test_data)\n",
    "    true_val = test['labels'].values\n",
    "    auroc_test, auprc_test, f1_test = utility.get_scores(true_val, pred_val)\n",
    "    test_dict = {'AUROC_test': auroc_test, \n",
    "                 'AUPRC_test': auroc_test, \n",
    "                 'f1_test': f1_test}\n",
    "    \n",
    "    # Append to our Dataframe\n",
    "    new_row = {'Name': model.__name__ + '_half' + str(half)} if half else {'Name': model.__name__}\n",
    "    new_row.update(cv_dict)\n",
    "    new_row.update(test_dict)\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    return (best_estimator, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1, 10, 100],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.7817207800759418\n",
      "The best score was: 0.9813946282451627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lg_best_estimator, f1_eval_df = evaluate_model(LogisticRegression, params, f1_eval_df, train, test, 'f1')\n",
    "_, auroc_eval_df = evaluate_model(LogisticRegression, params, auroc_eval_df, train, test, 'roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ['linear', 'rbf', 'poly'],\n",
    "          'C': [0.1, 1, 10, 100],\n",
    "          'class_weight': [None, 'balanced'],\n",
    "          'gamma': ['auto', 'scale']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.8188472249423642\n",
      "The best score was: 0.9854422661809914\n"
     ]
    }
   ],
   "source": [
    "svc_best_estimator, f1_eval_df = evaluate_model(SVC, params, f1_eval_df, train, test, 'f1')\n",
    "_, auroc_eval_df = evaluate_model(SVC, params, auroc_eval_df, train, test, 'roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':[10, 50, 100, 500],\n",
    "          'class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.3336355530434478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.9813361234430813\n"
     ]
    }
   ],
   "source": [
    "rfc_best_estimator, f1_eval_df = evaluate_model(RandomForestClassifier, params, f1_eval_df, train, test, 'f1')\n",
    "_, auroc_eval_df = evaluate_model(RandomForestClassifier, params, auroc_eval_df, train, test, 'roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gaussian Process Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, PairwiseKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel' : [RBF(), PairwiseKernel()]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.7282852086438152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.9757707661004833\n"
     ]
    }
   ],
   "source": [
    "gpc_best_estimator, f1_eval_df = evaluate_model(GaussianProcessClassifier, params, f1_eval_df, train, test, 'f1')\n",
    "_, auroc_eval_df = evaluate_model(GaussianProcessClassifier, params, auroc_eval_df, train, test, 'roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM + String kernels (using SHOGUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import shogun as sg\n",
    "\n",
    "features_train = sg.StringCharFeatures(list(X_train), sg.DNA)\n",
    "labels_train = sg.BinaryLabels(y_train.astype(int))\n",
    "features_test = sg.StringCharFeatures(list(X_test), sg.DNA)\n",
    "labels_test = sg.BinaryLabels(y_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Degree Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform optimization via grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Root\n",
    "#param_tree_root = sg.ModelSelectionParameters()\n",
    "\n",
    "#Parameter C\n",
    "#C = sg.ModelSelectionParameters(\"C\")\n",
    "#param_tree_root.append_child(C)\n",
    "#C.build_values(1, 10, sg.R_LINEAR, 1, 2)\n",
    "#C.set_values(1,2,3)\n",
    "\n",
    "#kernel = sg.WeightedDegreeStringKernel(features_train, features_train, kernel_degree)\n",
    "#svm = sg.LibSVM(C, kernel, labels_train)\n",
    "\n",
    "#C.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score F1Measure 0.8151239188107746\n"
     ]
    }
   ],
   "source": [
    "C = 2\n",
    "kernel_degree = 3\n",
    "\n",
    "kernel = sg.WeightedDegreeStringKernel(features_train, features_train, kernel_degree)\n",
    "svm = sg.LibSVM(C, kernel, labels_train)\n",
    "\n",
    "# Cross validation\n",
    "stratified_split = sg.StratifiedCrossValidationSplitting(labels_train, 5)\n",
    "metric = sg.F1Measure()\n",
    "cross = sg.CrossValidation(svm, features_train, labels_train, stratified_split, metric)\n",
    "# 25 runs and 95% confidence intervals\n",
    "cross.set_num_runs(25)\n",
    "cross.set_autolock(False)\n",
    "result = cross.evaluate()\n",
    "cv_score = sg.CrossValidationResult.obtain_from_generic(result).get_mean()\n",
    "print(\"CV score\", metric.get_name(), cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on whole train dataset to evaluate test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.train()\n",
    "pred_val = svm.apply(features_test).get_labels()\n",
    "auroc, auprc, f1_test = utility.get_scores(y_test.astype(int), pred_val)\n",
    "    \n",
    "# Append to our Dataframe\n",
    "f1_eval_df = f1_eval_df.append({'Name': 'WDK_' + str(kernel_degree), 'f1_cv':cv_score, 'AUROC_test':auroc, 'AUPRC_test': auprc, 'f1_test':f1_test}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed Degree String Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score F1Measure 0.7827243023971523\n"
     ]
    }
   ],
   "source": [
    "C = 2\n",
    "kernel_degree = 3\n",
    "\n",
    "kernel = sg.FixedDegreeStringKernel(features_train, features_train, kernel_degree)\n",
    "svm = sg.LibSVM(C, kernel, labels_train)\n",
    "\n",
    "# Cross validation\n",
    "stratified_split = sg.StratifiedCrossValidationSplitting(labels_train, 5)\n",
    "metric = sg.F1Measure()\n",
    "cross = sg.CrossValidation(svm, features_train, labels_train, stratified_split, metric)\n",
    "# 25 runs and 95% confidence intervals\n",
    "cross.set_num_runs(25)\n",
    "cross.set_autolock(False)\n",
    "result = cross.evaluate()\n",
    "cv_score = sg.CrossValidationResult.obtain_from_generic(result).get_mean()\n",
    "print(\"CV score\", metric.get_name(), cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on whole train dataset to evaluate test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.train()\n",
    "pred_val = svm.apply(features_test).get_labels()\n",
    "auroc, auprc, f1_test = utility.get_scores(y_test.astype(int), pred_val)\n",
    "    \n",
    "# Append to our Dataframe\n",
    "f1_eval_df = f1_eval_df.append({'Name': 'FDK_' + str(kernel_degree), 'f1_cv':cv_score, 'AUROC_test':auroc, 'AUPRC_test': auprc, 'f1_test':f1_test}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oligo String Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score F1Measure 0.7336453201970443\n"
     ]
    }
   ],
   "source": [
    "C = 2\n",
    "kernel_degree = 3\n",
    "kernel_width = 10\n",
    "\n",
    "kernel = sg.OligoStringKernel(features_train, features_train, kernel_degree, kernel_width)\n",
    "svm = sg.LibSVM(C, kernel, labels_train)\n",
    "\n",
    "# Cross validation\n",
    "stratified_split = sg.StratifiedCrossValidationSplitting(labels_train, 5)\n",
    "metric = sg.F1Measure()\n",
    "cross = sg.CrossValidation(svm, features_train, labels_train, stratified_split, metric)\n",
    "# 25 runs and 95% confidence intervals\n",
    "cross.set_num_runs(1)\n",
    "cross.set_autolock(False)\n",
    "result = cross.evaluate()\n",
    "cv_score = sg.CrossValidationResult.obtain_from_generic(result).get_mean()\n",
    "print(\"CV score\", metric.get_name(), cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on whole train dataset to evaluate test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.train()\n",
    "pred_val = svm.apply(features_test).get_labels()\n",
    "auroc, auprc, f1_test = utility.get_scores(y_test.astype(int), pred_val)\n",
    "    \n",
    "# Append to our Dataframe\n",
    "f1_eval_df = f1_eval_df.append({'Name': 'OSK_' + str(kernel_degree) + '_' + str(kernel_width),\n",
    "                                'f1_cv':cv_score, 'AUROC_test':auroc, 'AUPRC_test': auprc, 'f1_test':f1_test}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Degree Position String Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score F1Measure 0.7848986284156476\n"
     ]
    }
   ],
   "source": [
    "C = 2\n",
    "kernel_degree = 1\n",
    "\n",
    "kernel = sg.WeightedDegreePositionStringKernel(features_train, features_train, kernel_degree)\n",
    "svm = sg.LibSVM(C, kernel, labels_train)\n",
    "\n",
    "# Cross validation\n",
    "stratified_split = sg.StratifiedCrossValidationSplitting(labels_train, 5)\n",
    "metric = sg.F1Measure()\n",
    "cross = sg.CrossValidation(svm, features_train, labels_train, stratified_split, metric)\n",
    "# 25 runs and 95% confidence intervals\n",
    "cross.set_num_runs(25)\n",
    "cross.set_autolock(False)\n",
    "result = cross.evaluate()\n",
    "cv_score = sg.CrossValidationResult.obtain_from_generic(result).get_mean()\n",
    "print(\"CV score\", metric.get_name(), cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on whole train dataset to evaluate test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.train()\n",
    "pred_val = svm.apply(features_test).get_labels()\n",
    "auroc, auprc, f1_test = utility.get_scores(y_test.astype(int), pred_val)\n",
    "    \n",
    "# Append to our Dataframe\n",
    "f1_eval_df = f1_eval_df.append({'Name': 'WDPSK_' + str(kernel_degree), 'f1_cv':cv_score, 'AUROC_test':auroc, 'AUPRC_test': auprc, 'f1_test':f1_test}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Kernel Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we combine the better performing previous kernels mixed via a weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    C = 1\n",
    "\n",
    "    #poly_kernel = sg.PolyKernel(dot_features, dot_features, 3, True, 10)\n",
    "    WD_kernel = sg.WeightedDegreeStringKernel(3)\n",
    "    #WDP_kernel = sg.WeightedDegreePositionStringKernel()\n",
    "\n",
    "    combined_kernel = sg.CombinedKernel()\n",
    "    combined_kernel.append_kernel(WD_kernel)\n",
    "    #combined_kernel.append_kernel(WDP_kernel)\n",
    "    combined_kernel.init(features_train, features_train)\n",
    "\n",
    "    svm = sg.LibSVM(C, combined_kernel, labels_train)\n",
    "\n",
    "    # Cross validation\n",
    "    stratified_split = sg.StratifiedCrossValidationSplitting(labels_train, 5)\n",
    "    metric = sg.F1Measure()\n",
    "    cross = sg.CrossValidation(svm, features_train, labels_train, stratified_split, metric)\n",
    "    # 25 runs and 95% confidence intervals\n",
    "    cross.set_num_runs(25)\n",
    "    cross.set_autolock(False)\n",
    "    result = cross.evaluate()\n",
    "    cv_score = sg.CrossValidationResult.obtain_from_generic(result).get_mean()\n",
    "    print(\"CV score\", metric.get_name(), cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train on whole train dataset to evaluate test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    svm.train()\n",
    "    pred_val = svm.apply(features_test).get_labels()\n",
    "    auroc, auprc, f1_test = utility.get_scores(y_test.astype(int), pred_val)\n",
    "\n",
    "    # Append to our Dataframe\n",
    "    f1_eval_df = f1_eval_df.append({'Name': 'MKL', 'f1_cv':cv_score, 'AUROC_test':auroc, 'AUPRC_test': auprc, 'f1_test':f1_test}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import BatchNormalization,Conv1D,Input,Add,Dense,Flatten\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
    "    y_correct = tf.cast(tf.equal(y_true,y_pred),\"int32\")\n",
    "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
    "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
    "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
    "    precision = sum_correct / sum_pred\n",
    "    recall = sum_correct / sum_true\n",
    "    f_score = 2 * precision * recall / (1 * precision + recall)\n",
    "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
    "    return tf.reduce_mean(f_score)\n",
    "\n",
    "def add_RB(x):\n",
    "    xout=BatchNormalization()(x)\n",
    "    xout=Conv1D(filters=32,kernel_size=11,dilation_rate=1,padding='same',activation='relu')(x)\n",
    "    xout=BatchNormalization()(xout)\n",
    "    xout=Conv1D(filters=32,kernel_size=11,dilation_rate=1,padding='same',activation='relu')(xout)\n",
    "    return xout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1760/1760 [==============================] - 6s 3ms/step - loss: 1.3098 - f1: 0.0744\n",
      "Epoch 2/20\n",
      "1760/1760 [==============================] - 0s 214us/step - loss: 0.7452 - f1: 0.0841\n",
      "Epoch 3/20\n",
      "1760/1760 [==============================] - 0s 219us/step - loss: 0.4338 - f1: 0.0852\n",
      "Epoch 4/20\n",
      "1760/1760 [==============================] - 0s 221us/step - loss: 0.2688 - f1: 0.0898\n",
      "Epoch 5/20\n",
      "1760/1760 [==============================] - 0s 223us/step - loss: 0.1939 - f1: 0.0886\n",
      "Epoch 6/20\n",
      "1760/1760 [==============================] - 0s 225us/step - loss: 0.1257 - f1: 0.0898\n",
      "Epoch 7/20\n",
      "1760/1760 [==============================] - 0s 222us/step - loss: 0.0924 - f1: 0.0898\n",
      "Epoch 8/20\n",
      "1760/1760 [==============================] - 0s 223us/step - loss: 0.0820 - f1: 0.0898\n",
      "Epoch 9/20\n",
      "1760/1760 [==============================] - 0s 231us/step - loss: 0.0571 - f1: 0.0898\n",
      "Epoch 10/20\n",
      "1760/1760 [==============================] - 0s 239us/step - loss: 0.0437 - f1: 0.0898\n",
      "Epoch 11/20\n",
      "1760/1760 [==============================] - 0s 243us/step - loss: 0.0379 - f1: 0.0898\n",
      "Epoch 12/20\n",
      "1760/1760 [==============================] - 0s 232us/step - loss: 0.0295 - f1: 0.0898\n",
      "Epoch 13/20\n",
      "1760/1760 [==============================] - 0s 229us/step - loss: 0.0252 - f1: 0.0898\n",
      "Epoch 14/20\n",
      "1760/1760 [==============================] - 1s 295us/step - loss: 0.0218 - f1: 0.0898\n",
      "Epoch 15/20\n",
      "1760/1760 [==============================] - 0s 224us/step - loss: 0.0194 - f1: 0.0898\n",
      "Epoch 16/20\n",
      "1760/1760 [==============================] - 0s 232us/step - loss: 0.0165 - f1: 0.0898\n",
      "Epoch 17/20\n",
      "1760/1760 [==============================] - 0s 230us/step - loss: 0.0141 - f1: 0.0898\n",
      "Epoch 18/20\n",
      "1760/1760 [==============================] - 0s 228us/step - loss: 0.0134 - f1: 0.0898\n",
      "Epoch 19/20\n",
      "1760/1760 [==============================] - 0s 230us/step - loss: 0.0105 - f1: 0.0898\n",
      "Epoch 20/20\n",
      "1760/1760 [==============================] - 0s 223us/step - loss: 0.0091 - f1: 0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py:7626: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2961: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x=Input(shape=[328,1])\n",
    "\n",
    "x1=Conv1D(filters=32,kernel_size=1,dilation_rate=1,padding='same',activation='relu')(x)\n",
    "\n",
    "xrb=add_RB(x1)\n",
    "#xrb=add_RB(xrb)\n",
    "#xrb=add_RB(xrb)\n",
    "#xrb=add_RB(xrb)\n",
    "\n",
    "x2=Conv1D(filters=32,kernel_size=1,dilation_rate=1,padding='same',activation='relu')(xrb)\n",
    "x3=Conv1D(filters=32,kernel_size=1,dilation_rate=1,padding='same',activation='relu')(x1)\n",
    "\n",
    "xout=Conv1D(filters=1,kernel_size=1,dilation_rate=1,padding='same',activation='relu')(Add()([x2,x3]))\n",
    "xout=Flatten()(xout)\n",
    "xout=Dense(units=1,activation='sigmoid')(xout)\n",
    "\n",
    "model=Model(x,xout)\n",
    "model.compile(optimizer=Adam(),loss='binary_crossentropy',metrics=[f1])\n",
    "class_wt={0:1,1:15}\n",
    "\n",
    "train_data = np.vstack(train['DNA'].values)[:,:,None]\n",
    "test_data  = np.vstack(test['DNA'].values)[:,:,None]\n",
    "\n",
    "train_val=train['labels'].values\n",
    "train_val[train_val==-1]=0\n",
    "model.fit(x=train_data,y=train_val,batch_size=64,epochs=20,class_weight=class_wt)\n",
    "\n",
    "pred_val=(model.predict(test_data)>0.5).astype(np.int)\n",
    "true_val=test['labels']\n",
    "true_val[true_val==-1]=0\n",
    "dl_mtr=utility.get_scores(true_val,pred_val)\n",
    "dl_f1=utility.f1_score(true_val,pred_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_eval_df = f1_eval_df.append({'Name': 'DL Model', 'AUROC_test':dl_mtr[0], 'AUPRC_test': dl_mtr[1], 'f1_test':dl_f1}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC half string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we only use the first or second half of the dna sequences in order to assess the influence of each substring in the accuracy of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First substring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ['linear', 'rbf', 'poly'],\n",
    "          'C': [0.1, 1, 10, 100],\n",
    "          'class_weight': [None, 'balanced'],\n",
    "          'gamma': ['auto', 'scale']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.7901082530012139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juaaa\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.9783415356339815\n"
     ]
    }
   ],
   "source": [
    "svc_best_estimator_half, f1_eval_df = evaluate_model(SVC, params, f1_eval_df, train, test, 'f1', 1)\n",
    "_, auroc_eval_df = evaluate_model(SVC, params, auroc_eval_df, train, test, 'roc_auc', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second substring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'kernel': ['linear', 'rbf', 'poly'],\n",
    "          'C': [0.1, 1, 10, 100],\n",
    "          'class_weight': [None, 'balanced'],\n",
    "          'gamma': ['auto', 'scale']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score was: 0.23925972623629105\n",
      "The best score was: 0.6995015124893226\n"
     ]
    }
   ],
   "source": [
    "svc_best_estimator_half, f1_eval_df = evaluate_model(SVC, params, f1_eval_df, train, test, 'f1', 2)\n",
    "_, auroc_eval_df = evaluate_model(SVC, params, auroc_eval_df, train, test, 'roc_auc', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUROC_cv</th>\n",
       "      <th>f1_cv</th>\n",
       "      <th>AUROC_test</th>\n",
       "      <th>AUPRC_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.981414</td>\n",
       "      <td>0.781721</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.984314</td>\n",
       "      <td>0.818847</td>\n",
       "      <td>0.930426</td>\n",
       "      <td>0.930426</td>\n",
       "      <td>0.850575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.922525</td>\n",
       "      <td>0.333636</td>\n",
       "      <td>0.617791</td>\n",
       "      <td>0.617791</td>\n",
       "      <td>0.377358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.975771</td>\n",
       "      <td>0.728285</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WDK_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.815124</td>\n",
       "      <td>0.854630</td>\n",
       "      <td>0.839529</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FDK_3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.782724</td>\n",
       "      <td>0.838957</td>\n",
       "      <td>0.786481</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OSK_3_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.733645</td>\n",
       "      <td>0.816403</td>\n",
       "      <td>0.773958</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WDPSK_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784899</td>\n",
       "      <td>0.922290</td>\n",
       "      <td>0.874414</td>\n",
       "      <td>0.867470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DL Model</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918521</td>\n",
       "      <td>0.844481</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC_half1</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>0.790108</td>\n",
       "      <td>0.934793</td>\n",
       "      <td>0.934793</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC_half2</td>\n",
       "      <td>0.689351</td>\n",
       "      <td>0.239260</td>\n",
       "      <td>0.627363</td>\n",
       "      <td>0.627363</td>\n",
       "      <td>0.244131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  AUROC_cv     f1_cv  AUROC_test  AUPRC_test  \\\n",
       "0          LogisticRegression  0.981414  0.781721    0.869646    0.869646   \n",
       "1                         SVC  0.984314  0.818847    0.930426    0.930426   \n",
       "2      RandomForestClassifier  0.922525  0.333636    0.617791    0.617791   \n",
       "3   GaussianProcessClassifier  0.975771  0.728285    0.868390    0.868390   \n",
       "4                       WDK_3       NaN  0.815124    0.854630    0.839529   \n",
       "5                       FDK_3       NaN  0.782724    0.838957    0.786481   \n",
       "6                    OSK_3_10       NaN  0.733645    0.816403    0.773958   \n",
       "7                     WDPSK_1       NaN  0.784899    0.922290    0.874414   \n",
       "8                    DL Model       NaN       NaN    0.918521    0.844481   \n",
       "9                   SVC_half1  0.977560  0.790108    0.934793    0.934793   \n",
       "10                  SVC_half2  0.689351  0.239260    0.627363    0.627363   \n",
       "\n",
       "     f1_test  \n",
       "0   0.771084  \n",
       "1   0.850575  \n",
       "2   0.377358  \n",
       "3   0.761905  \n",
       "4   0.810811  \n",
       "5   0.763158  \n",
       "6   0.739726  \n",
       "7   0.867470  \n",
       "8   0.837209  \n",
       "9   0.808511  \n",
       "10  0.244131  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>AUROC_cv</th>\n",
       "      <th>f1_cv</th>\n",
       "      <th>AUROC_test</th>\n",
       "      <th>AUPRC_test</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.981395</td>\n",
       "      <td>0.781721</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.869646</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.985442</td>\n",
       "      <td>0.709872</td>\n",
       "      <td>0.930366</td>\n",
       "      <td>0.930366</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.981336</td>\n",
       "      <td>0.149731</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.975771</td>\n",
       "      <td>0.728285</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.868390</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC_half1</td>\n",
       "      <td>0.978342</td>\n",
       "      <td>0.663496</td>\n",
       "      <td>0.915291</td>\n",
       "      <td>0.915291</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_half2</td>\n",
       "      <td>0.699502</td>\n",
       "      <td>0.231438</td>\n",
       "      <td>0.561199</td>\n",
       "      <td>0.561199</td>\n",
       "      <td>0.201681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  AUROC_cv     f1_cv  AUROC_test  AUPRC_test  \\\n",
       "0         LogisticRegression  0.981395  0.781721    0.869646    0.869646   \n",
       "1                        SVC  0.985442  0.709872    0.930366    0.930366   \n",
       "2     RandomForestClassifier  0.981336  0.149731    0.583333    0.583333   \n",
       "3  GaussianProcessClassifier  0.975771  0.728285    0.868390    0.868390   \n",
       "4                  SVC_half1  0.978342  0.663496    0.915291    0.915291   \n",
       "5                  SVC_half2  0.699502  0.231438    0.561199    0.561199   \n",
       "\n",
       "    f1_test  \n",
       "0  0.771084  \n",
       "1  0.722222  \n",
       "2  0.285714  \n",
       "3  0.761905  \n",
       "4  0.650000  \n",
       "5  0.201681  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auroc_eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kernelized SVM works the best, but not much better than other simpler models such as logistic regression.\n",
    "- String kernels didn't improve over polymial kernel.\n",
    "- First half of the dna sequences holds most of the relevant information for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
