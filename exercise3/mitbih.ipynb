{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MITBIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import models\n",
    "import types\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.mixture\n",
    "from sklearn.metrics import roc_curve,precision_recall_curve,auc,accuracy_score,f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(model_name,Y_test,pred_test,metrics_df):\n",
    "    pred_test_temp = np.argmax(pred_test,axis=-1)\n",
    "    Y_test_temp = np.argmax(Y_test,axis=-1)\n",
    "    acc = accuracy_score(Y_test_temp, pred_test_temp)\n",
    "    curr_metrics = {'Name': model_name,\"ACC\": acc}\n",
    "    metrics_df = metrics_df.append(curr_metrics, ignore_index=True)\n",
    "    return metrics_df\n",
    "\n",
    "def visualize(df,title):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    np.random.seed(0)\n",
    "    n_sub_plots = 5\n",
    "    for i in range(n_sub_plots):\n",
    "        plt.subplot(n_sub_plots, 1, i + 1)\n",
    "        plt.plot(df.iloc[np.random.choice(len(df[1])), :])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "lstm_out = 100\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "df_train = pd.read_csv(\"exercise_data/heartbeat/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"exercise_data/heartbeat/mitbih_test.csv\", header=None)\n",
    "\n",
    "# 87556 samples\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(186))].values)[..., np.newaxis]\n",
    "Y = keras.utils.to_categorical(Y)\n",
    "\n",
    "# 21890 samples\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(186))].values)[..., np.newaxis]\n",
    "Y_test = keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(df_train, 'Training Set EEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data=[],columns=['Name','ACC'])\n",
    "\n",
    "models_ = [\n",
    "    #sklearn.mixture.BayesianGaussianMixture(n_components=5),\n",
    "    sklearn.mixture.GaussianMixture(n_components=5),\n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    models.Residual_CNN(outputs=5, epochs=15),\n",
    "    models.CNN_Model(outputs=5, epochs=15),\n",
    "    models.LSTM_Model(outputs=5, epochs=15),\n",
    "]\n",
    "\n",
    "params = [\n",
    "    #GMM\n",
    "    {\n",
    "\n",
    "    },\n",
    "    # RandomForestClassifier\n",
    "    {\n",
    "        'n_estimators': [10, 100, 200],\n",
    "        'n_jobs': [-1]\n",
    "    },\n",
    "    # Residual_CNN\n",
    "    {\n",
    "        'deepness': range(1, 6),\n",
    "    },\n",
    "    # CNN_Model\n",
    "    {\n",
    "        'conv1_size': [16, 32],\n",
    "        'conv2_size': [32, 64],\n",
    "        'conv3_size': [128, 256],\n",
    "        'dense_size': [16, 32, 64],\n",
    "    },\n",
    "    # LSTM\n",
    "    {\n",
    "        'hidden': [64],\n",
    "        'dense': [64],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = []\n",
    "for param, model in zip(params, models_):\n",
    "    clf = RandomizedSearchCV(model, param, cv=2,n_iter=3, verbose=2)\n",
    "    if type(model) == RandomForestClassifier or \\\n",
    "        type(model) == sklearn.mixture.GaussianMixture or \\\n",
    "        type(model) == sklearn.mixture.BayesianGaussianMixture:\n",
    "        clf.fit(np.squeeze(X), np.argmax(Y,axis=-1))\n",
    "        model = clf.best_estimator_\n",
    "        model.getScores = types.MethodType(models.CNN_Model.getScores_multi, model)\n",
    "        _, metrics_df = model.getScores(np.squeeze(X_test), Y_test, metrics_df)\n",
    "    else:\n",
    "        clf.fit(X, Y)\n",
    "        model = clf.best_estimator_\n",
    "        pred, metrics_df = model.getScores_multi(X_test, Y_test, metrics_df)\n",
    "        model_preds.append(pred)\n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = np.array(model_preds)\n",
    "model_preds = np.squeeze(model_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = np.mean(model_preds,axis=0)\n",
    "metrics_df = getScores('Ensemble(Avg)',Y_test=Y_test,pred_test=avg_pred,metrics_df=metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression(n_jobs=-1,multi_class = 'multinomial',solver='lbfgs')\n",
    "X_lg = np.transpose(model_preds,[1,2,0])\n",
    "n_samples = X_lg.shape[0]\n",
    "X_lg = np.reshape(X_lg,[n_samples,-1])\n",
    "lg.fit(X_lg,np.argmax(Y_test,axis=-1))\n",
    "lg_pred = lg.predict_proba(X_lg)\n",
    "metrics_df = getScores('Ensemble(LG)',Y_test=Y_test,pred_test=lg_pred,metrics_df=metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
