{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MITBIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import models\n",
    "import types\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.mixture\n",
    "from sklearn.metrics import roc_curve,precision_recall_curve,auc,accuracy_score,f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(model_name,Y_test,pred_test,metrics_df):\n",
    "    pred_test_temp = np.argmax(pred_test,axis=-1)\n",
    "    Y_test_temp = np.argmax(Y_test,axis=-1)\n",
    "    acc = accuracy_score(Y_test_temp, pred_test_temp)\n",
    "    curr_metrics = {'Name': model_name,\"ACC\": acc}\n",
    "    metrics_df = metrics_df.append(curr_metrics, ignore_index=True)\n",
    "    return metrics_df\n",
    "\n",
    "def visualize(df,title):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    np.random.seed(0)\n",
    "    n_sub_plots = 5\n",
    "    for i in range(n_sub_plots):\n",
    "        plt.subplot(n_sub_plots, 1, i + 1)\n",
    "        plt.plot(df.iloc[np.random.choice(len(df[1])), :])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "lstm_out = 100\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "df_train = pd.read_csv(\"exercise_data/heartbeat/mitbih_train.csv\", header=None)\n",
    "df_train = df_train.sample(frac=1)\n",
    "df_test = pd.read_csv(\"exercise_data/heartbeat/mitbih_test.csv\", header=None)\n",
    "\n",
    "# 87556 samples\n",
    "Y = np.array(df_train[187].values).astype(np.int8)\n",
    "X = np.array(df_train[list(range(186))].values)[..., np.newaxis]\n",
    "Y = keras.utils.to_categorical(Y)\n",
    "\n",
    "# 21890 samples\n",
    "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
    "X_test = np.array(df_test[list(range(186))].values)[..., np.newaxis]\n",
    "Y_test = keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(df_train, 'Training Set EEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(data=[],columns=['Name','ACC'])\n",
    "\n",
    "models_ = [\n",
    "    #sklearn.mixture.BayesianGaussianMixture(n_components=5),\n",
    "    sklearn.mixture.GaussianMixture(n_components=5),\n",
    "    RandomForestClassifier(n_jobs=-1),\n",
    "    models.Residual_CNN(outputs=5, epochs=15),\n",
    "    models.CNN_Model(outputs=5, epochs=15),\n",
    "    models.LSTM_Model(outputs=5, epochs=15),\n",
    "]\n",
    "\n",
    "params = [\n",
    "    #GMM\n",
    "    {\n",
    "\n",
    "    },\n",
    "    # RandomForestClassifier\n",
    "    {\n",
    "        'n_estimators': [10, 100, 200],\n",
    "        'n_jobs': [-1]\n",
    "    },\n",
    "    # Residual_CNN\n",
    "    {\n",
    "        'deepness': range(1, 6),\n",
    "    },\n",
    "    # CNN_Model\n",
    "    {\n",
    "        'conv1_size': [16, 32],\n",
    "        'conv2_size': [32, 64],\n",
    "        'conv3_size': [128, 256],\n",
    "        'dense_size': [16, 32, 64],\n",
    "    },\n",
    "    # LSTM\n",
    "    {\n",
    "        'hidden': [64],\n",
    "        'dense': [64],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  51.6s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   52.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  44.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name       ACC\n",
      "0  GaussianMixture  0.451261\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] n_jobs=-1, n_estimators=10 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_jobs=-1, n_estimators=10, total=   2.1s\n",
      "[CV] n_jobs=-1, n_estimators=10 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... n_jobs=-1, n_estimators=10, total=   1.3s\n",
      "[CV] n_jobs=-1, n_estimators=100 .....................................\n",
      "[CV] ...................... n_jobs=-1, n_estimators=100, total=   8.8s\n",
      "[CV] n_jobs=-1, n_estimators=100 .....................................\n",
      "[CV] ...................... n_jobs=-1, n_estimators=100, total=   8.4s\n",
      "[CV] n_jobs=-1, n_estimators=200 .....................................\n",
      "[CV] ...................... n_jobs=-1, n_estimators=200, total=  16.9s\n",
      "[CV] n_jobs=-1, n_estimators=200 .....................................\n",
      "[CV] ...................... n_jobs=-1, n_estimators=200, total=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   55.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name       ACC\n",
      "0         GaussianMixture  0.451261\n",
      "1  RandomForestClassifier  0.974100\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "[CV] deepness=2 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39399 samples, validate on 4378 samples\n",
      "WARNING:tensorflow:From /home/martin/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 2.7471 - acc: 0.8294\n",
      "Epoch 00001: val_acc improved from -inf to 0.82275, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 7s 172us/sample - loss: 2.7420 - acc: 0.8297 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 2/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 2.7405 - acc: 0.8300\n",
      "Epoch 00002: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 129us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 3/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 2.7441 - acc: 0.8298\n",
      "Epoch 00003: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 130us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 4/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 2.7410 - acc: 0.8299\n",
      "Epoch 00004: val_acc did not improve from 0.82275\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "39399/39399 [==============================] - 5s 134us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 5/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 2.7454 - acc: 0.8297\n",
      "Epoch 00005: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 134us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 6/15\n",
      "39040/39399 [============================>.] - ETA: 0s - loss: 2.7430 - acc: 0.8298\n",
      "Epoch 00006: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 00006: early stopping\n",
      "43777/43777 [==============================] - 1s 34us/sample - loss: 2.7993 - acc: 0.8263\n",
      "43777/43777 [==============================] - 1s 32us/sample - loss: 2.7540 - acc: 0.8291\n",
      "[CV] ....................................... deepness=2, total=  36.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   38.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] deepness=2 ......................................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 2.7725 - acc: 0.8272\n",
      "Epoch 00001: val_acc improved from -inf to 0.81247, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 7s 169us/sample - loss: 2.7732 - acc: 0.8272 - val_loss: 3.0226 - val_acc: 0.8125\n",
      "Epoch 2/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 2.7736 - acc: 0.8279\n",
      "Epoch 00002: val_acc did not improve from 0.81247\n",
      "39399/39399 [==============================] - 5s 129us/sample - loss: 2.7745 - acc: 0.8279 - val_loss: 3.0226 - val_acc: 0.8125\n",
      "Epoch 3/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 2.7756 - acc: 0.8278\n",
      "Epoch 00003: val_acc did not improve from 0.81247\n",
      "39399/39399 [==============================] - 5s 135us/sample - loss: 2.7745 - acc: 0.8279 - val_loss: 3.0226 - val_acc: 0.8125\n",
      "Epoch 4/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 2.7713 - acc: 0.8281\n",
      "Epoch 00004: val_acc did not improve from 0.81247\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "39399/39399 [==============================] - 5s 133us/sample - loss: 2.7745 - acc: 0.8279 - val_loss: 3.0226 - val_acc: 0.8125\n",
      "Epoch 5/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 2.7726 - acc: 0.8280\n",
      "Epoch 00005: val_acc did not improve from 0.81247\n",
      "39399/39399 [==============================] - 5s 132us/sample - loss: 2.7745 - acc: 0.8279 - val_loss: 3.0226 - val_acc: 0.8125\n",
      "Epoch 6/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 2.7742 - acc: 0.8279\n",
      "Epoch 00006: val_acc did not improve from 0.81247\n",
      "39399/39399 [==============================] - 5s 131us/sample - loss: 2.7745 - acc: 0.8279 - val_loss: 3.0226 - val_acc: 0.8125\n",
      "Epoch 00006: early stopping\n",
      "43777/43777 [==============================] - 1s 33us/sample - loss: 2.7540 - acc: 0.8291\n",
      "43777/43777 [==============================] - 1s 34us/sample - loss: 2.7993 - acc: 0.8263\n",
      "[CV] ....................................... deepness=2, total=  35.8s\n",
      "[CV] deepness=5 ......................................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 2.7453 - acc: 0.8296\n",
      "Epoch 00001: val_acc improved from -inf to 0.82275, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 7s 178us/sample - loss: 2.7412 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 2/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 2.7430 - acc: 0.8298\n",
      "Epoch 00002: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 3/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 2.7470 - acc: 0.8296\n",
      "Epoch 00003: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 129us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 4/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 2.7422 - acc: 0.8299\n",
      "Epoch 00004: val_acc did not improve from 0.82275\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "39399/39399 [==============================] - 5s 139us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 5/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 2.7420 - acc: 0.8299\n",
      "Epoch 00005: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 131us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 6/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 2.7462 - acc: 0.8296\n",
      "Epoch 00006: val_acc did not improve from 0.82275\n",
      "39399/39399 [==============================] - 5s 130us/sample - loss: 2.7426 - acc: 0.8298 - val_loss: 2.8569 - val_acc: 0.8228\n",
      "Epoch 00006: early stopping\n",
      "43777/43777 [==============================] - 2s 35us/sample - loss: 2.7993 - acc: 0.8263\n",
      "43777/43777 [==============================] - 2s 35us/sample - loss: 2.7540 - acc: 0.8291\n",
      "[CV] ....................................... deepness=5, total=  36.7s\n",
      "[CV] deepness=5 ......................................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9242\n",
      "Epoch 00001: val_acc improved from -inf to 0.94564, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 7s 181us/sample - loss: 0.2671 - acc: 0.9245 - val_loss: 0.1918 - val_acc: 0.9456\n",
      "Epoch 2/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9432\n",
      "Epoch 00002: val_acc did not improve from 0.94564\n",
      "39399/39399 [==============================] - 5s 135us/sample - loss: 0.2025 - acc: 0.9432 - val_loss: 0.2067 - val_acc: 0.9420\n",
      "Epoch 3/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9420\n",
      "Epoch 00003: val_acc improved from 0.94564 to 0.95774, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 139us/sample - loss: 0.2037 - acc: 0.9419 - val_loss: 0.1476 - val_acc: 0.9577\n",
      "Epoch 4/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9516\n",
      "Epoch 00004: val_acc did not improve from 0.95774\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.1696 - acc: 0.9517 - val_loss: 0.2035 - val_acc: 0.9436\n",
      "Epoch 5/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9498\n",
      "Epoch 00005: val_acc did not improve from 0.95774\n",
      "39399/39399 [==============================] - 6s 143us/sample - loss: 0.1780 - acc: 0.9498 - val_loss: 0.1850 - val_acc: 0.9479\n",
      "Epoch 6/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9557\n",
      "Epoch 00006: val_acc did not improve from 0.95774\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "39399/39399 [==============================] - 6s 147us/sample - loss: 0.1586 - acc: 0.9557 - val_loss: 0.1756 - val_acc: 0.9529\n",
      "Epoch 7/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9661\n",
      "Epoch 00007: val_acc improved from 0.95774 to 0.96528, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 6s 140us/sample - loss: 0.1198 - acc: 0.9663 - val_loss: 0.1210 - val_acc: 0.9653\n",
      "Epoch 8/15\n",
      "39040/39399 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9705\n",
      "Epoch 00008: val_acc did not improve from 0.96528\n",
      "39399/39399 [==============================] - 5s 139us/sample - loss: 0.1059 - acc: 0.9705 - val_loss: 0.1200 - val_acc: 0.9644\n",
      "Epoch 9/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9716\n",
      "Epoch 00009: val_acc improved from 0.96528 to 0.96619, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 6s 141us/sample - loss: 0.0997 - acc: 0.9715 - val_loss: 0.1202 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9727\n",
      "Epoch 00010: val_acc did not improve from 0.96619\n",
      "39399/39399 [==============================] - 6s 143us/sample - loss: 0.0960 - acc: 0.9727 - val_loss: 0.1202 - val_acc: 0.9660\n",
      "Epoch 11/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9740\n",
      "Epoch 00011: val_acc did not improve from 0.96619\n",
      "39399/39399 [==============================] - 6s 141us/sample - loss: 0.0926 - acc: 0.9739 - val_loss: 0.1153 - val_acc: 0.9662\n",
      "Epoch 12/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9747\n",
      "Epoch 00012: val_acc improved from 0.96619 to 0.96642, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.0897 - acc: 0.9746 - val_loss: 0.1130 - val_acc: 0.9664\n",
      "Epoch 13/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9756\n",
      "Epoch 00013: val_acc improved from 0.96642 to 0.96802, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 134us/sample - loss: 0.0871 - acc: 0.9755 - val_loss: 0.1164 - val_acc: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9773\n",
      "Epoch 00014: val_acc did not improve from 0.96802\n",
      "39399/39399 [==============================] - 5s 130us/sample - loss: 0.0845 - acc: 0.9772 - val_loss: 0.1130 - val_acc: 0.9676\n",
      "Epoch 15/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9767\n",
      "Epoch 00015: val_acc improved from 0.96802 to 0.96916, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.0825 - acc: 0.9768 - val_loss: 0.1062 - val_acc: 0.9692\n",
      "43777/43777 [==============================] - 2s 37us/sample - loss: 0.0952 - acc: 0.9731\n",
      "43777/43777 [==============================] - 2s 37us/sample - loss: 0.0802 - acc: 0.9775\n",
      "[CV] ....................................... deepness=5, total= 1.5min\n",
      "[CV] deepness=1 ......................................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9275\n",
      "Epoch 00001: val_acc improved from -inf to 0.95180, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 7s 189us/sample - loss: 0.2597 - acc: 0.9276 - val_loss: 0.1926 - val_acc: 0.9518\n",
      "Epoch 2/15\n",
      "39040/39399 [============================>.] - ETA: 0s - loss: 0.1839 - acc: 0.9518\n",
      "Epoch 00002: val_acc improved from 0.95180 to 0.95729, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.1833 - acc: 0.9521 - val_loss: 0.1863 - val_acc: 0.9573\n",
      "Epoch 3/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9503\n",
      "Epoch 00003: val_acc improved from 0.95729 to 0.96185, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.1871 - acc: 0.9503 - val_loss: 0.1485 - val_acc: 0.9619\n",
      "Epoch 4/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9536\n",
      "Epoch 00004: val_acc did not improve from 0.96185\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.1764 - acc: 0.9536 - val_loss: 0.1939 - val_acc: 0.9418\n",
      "Epoch 5/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9535\n",
      "Epoch 00005: val_acc did not improve from 0.96185\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.1785 - acc: 0.9536 - val_loss: 0.1685 - val_acc: 0.9559\n",
      "Epoch 6/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9591\n",
      "Epoch 00006: val_acc did not improve from 0.96185\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "39399/39399 [==============================] - 6s 145us/sample - loss: 0.1574 - acc: 0.9591 - val_loss: 0.1885 - val_acc: 0.9564\n",
      "Epoch 7/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9696\n",
      "Epoch 00007: val_acc improved from 0.96185 to 0.96642, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.1206 - acc: 0.9696 - val_loss: 0.1214 - val_acc: 0.9664\n",
      "Epoch 8/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9727\n",
      "Epoch 00008: val_acc improved from 0.96642 to 0.96825, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.1080 - acc: 0.9727 - val_loss: 0.1131 - val_acc: 0.9683\n",
      "Epoch 9/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9741\n",
      "Epoch 00009: val_acc improved from 0.96825 to 0.96871, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.1008 - acc: 0.9742 - val_loss: 0.1103 - val_acc: 0.9687\n",
      "Epoch 10/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9757\n",
      "Epoch 00010: val_acc improved from 0.96871 to 0.97236, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.0945 - acc: 0.9756 - val_loss: 0.1026 - val_acc: 0.9724\n",
      "Epoch 11/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9764\n",
      "Epoch 00011: val_acc improved from 0.97236 to 0.97373, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 138us/sample - loss: 0.0895 - acc: 0.9764 - val_loss: 0.0978 - val_acc: 0.9737\n",
      "Epoch 12/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9767\n",
      "Epoch 00012: val_acc did not improve from 0.97373\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.0869 - acc: 0.9767 - val_loss: 0.1006 - val_acc: 0.9735\n",
      "Epoch 13/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9779\n",
      "Epoch 00013: val_acc improved from 0.97373 to 0.97533, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.0831 - acc: 0.9779 - val_loss: 0.0937 - val_acc: 0.9753\n",
      "Epoch 14/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9782\n",
      "Epoch 00014: val_acc improved from 0.97533 to 0.97556, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 137us/sample - loss: 0.0810 - acc: 0.9782 - val_loss: 0.0917 - val_acc: 0.9756\n",
      "Epoch 15/15\n",
      "39040/39399 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9796\n",
      "Epoch 00015: val_acc did not improve from 0.97556\n",
      "39399/39399 [==============================] - 5s 136us/sample - loss: 0.0781 - acc: 0.9795 - val_loss: 0.0903 - val_acc: 0.9746\n",
      "43777/43777 [==============================] - 2s 38us/sample - loss: 0.1019 - acc: 0.9744\n",
      "43777/43777 [==============================] - 2s 38us/sample - loss: 0.0763 - acc: 0.9797\n",
      "[CV] ....................................... deepness=1, total= 1.5min\n",
      "[CV] deepness=1 ......................................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9215\n",
      "Epoch 00001: val_acc improved from -inf to 0.94061, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 8s 200us/sample - loss: 0.2809 - acc: 0.9215 - val_loss: 0.2274 - val_acc: 0.9406\n",
      "Epoch 2/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9317\n",
      "Epoch 00002: val_acc did not improve from 0.94061\n",
      "39399/39399 [==============================] - 5s 138us/sample - loss: 0.2384 - acc: 0.9317 - val_loss: 0.2020 - val_acc: 0.9386\n",
      "Epoch 3/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9417\n",
      "Epoch 00003: val_acc improved from 0.94061 to 0.94198, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 139us/sample - loss: 0.2078 - acc: 0.9415 - val_loss: 0.1982 - val_acc: 0.9420\n",
      "Epoch 4/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9467\n",
      "Epoch 00004: val_acc improved from 0.94198 to 0.94587, saving model to Residual_CNN.h5\n",
      "39399/39399 [==============================] - 5s 139us/sample - loss: 0.1932 - acc: 0.9468 - val_loss: 0.1976 - val_acc: 0.9459\n",
      "Epoch 5/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.8781\n",
      "Epoch 00005: val_acc did not improve from 0.94587\n",
      "39399/39399 [==============================] - 5s 138us/sample - loss: 0.3995 - acc: 0.8783 - val_loss: 0.4216 - val_acc: 0.8760\n",
      "Epoch 6/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8693\n",
      "Epoch 00006: val_acc did not improve from 0.94587\n",
      "39399/39399 [==============================] - 5s 139us/sample - loss: 0.4096 - acc: 0.8691 - val_loss: 0.4549 - val_acc: 0.8442\n",
      "Epoch 7/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.4264 - acc: 0.8551\n",
      "Epoch 00007: val_acc did not improve from 0.94587\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "39399/39399 [==============================] - 6s 150us/sample - loss: 0.4264 - acc: 0.8552 - val_loss: 0.4460 - val_acc: 0.8472\n",
      "Epoch 8/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.4096 - acc: 0.8597\n",
      "Epoch 00008: val_acc did not improve from 0.94587\n",
      "39399/39399 [==============================] - 5s 138us/sample - loss: 0.4098 - acc: 0.8596 - val_loss: 0.4390 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.4075 - acc: 0.8597\n",
      "Epoch 00009: val_acc did not improve from 0.94587\n",
      "39399/39399 [==============================] - 5s 138us/sample - loss: 0.4074 - acc: 0.8598 - val_loss: 0.4367 - val_acc: 0.8497\n",
      "Epoch 00009: early stopping\n",
      "43777/43777 [==============================] - 2s 40us/sample - loss: 0.4043 - acc: 0.8602\n",
      "43777/43777 [==============================] - 2s 40us/sample - loss: 0.4094 - acc: 0.8590\n",
      "[CV] ....................................... deepness=1, total=  56.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/15\n",
      "78720/78798 [============================>.] - ETA: 0s - loss: 2.7623 - acc: 0.8285\n",
      "Epoch 00001: val_acc improved from -inf to 0.82047, saving model to Residual_CNN.h5\n",
      "78798/78798 [==============================] - 14s 181us/sample - loss: 2.7624 - acc: 0.8285 - val_loss: 2.8937 - val_acc: 0.8205\n",
      "Epoch 2/15\n",
      "78720/78798 [============================>.] - ETA: 0s - loss: 2.7629 - acc: 0.8286\n",
      "Epoch 00002: val_acc did not improve from 0.82047\n",
      "78798/78798 [==============================] - 11s 144us/sample - loss: 2.7637 - acc: 0.8285 - val_loss: 2.8937 - val_acc: 0.8205\n",
      "Epoch 3/15\n",
      "78624/78798 [============================>.] - ETA: 0s - loss: 2.7636 - acc: 0.8285\n",
      "Epoch 00003: val_acc did not improve from 0.82047\n",
      "78798/78798 [==============================] - 11s 144us/sample - loss: 2.7637 - acc: 0.8285 - val_loss: 2.8937 - val_acc: 0.8205\n",
      "Epoch 4/15\n",
      "78464/78798 [============================>.] - ETA: 0s - loss: 2.7635 - acc: 0.8285\n",
      "Epoch 00004: val_acc did not improve from 0.82047\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "78798/78798 [==============================] - 12s 151us/sample - loss: 2.7637 - acc: 0.8285 - val_loss: 2.8937 - val_acc: 0.8205\n",
      "Epoch 5/15\n",
      "78624/78798 [============================>.] - ETA: 0s - loss: 2.7651 - acc: 0.8284\n",
      "Epoch 00005: val_acc did not improve from 0.82047\n",
      "78798/78798 [==============================] - 11s 145us/sample - loss: 2.7637 - acc: 0.8285 - val_loss: 2.8937 - val_acc: 0.8205\n",
      "Epoch 6/15\n",
      "78592/78798 [============================>.] - ETA: 0s - loss: 2.7637 - acc: 0.8285\n",
      "Epoch 00006: val_acc did not improve from 0.82047\n",
      "78798/78798 [==============================] - 11s 145us/sample - loss: 2.7637 - acc: 0.8285 - val_loss: 2.8937 - val_acc: 0.8205\n",
      "Epoch 00006: early stopping\n",
      "                     Name       ACC\n",
      "0         GaussianMixture  0.451261\n",
      "1  RandomForestClassifier  0.974100\n",
      "2            Residual_CNN  0.827608\n",
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] dense_size=32, conv3_size=128, conv2_size=32, conv1_size=32 .....\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "WARNING:tensorflow:From /home/martin/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.4339 - acc: 0.8703\n",
      "Epoch 00001: val_acc improved from -inf to 0.90978, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 9s 235us/sample - loss: 0.4326 - acc: 0.8708 - val_loss: 0.3172 - val_acc: 0.9098\n",
      "Epoch 2/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.2710 - acc: 0.9260\n",
      "Epoch 00002: val_acc improved from 0.90978 to 0.94221, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.2711 - acc: 0.9260 - val_loss: 0.2215 - val_acc: 0.9422\n",
      "Epoch 3/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9396\n",
      "Epoch 00003: val_acc improved from 0.94221 to 0.94884, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 147us/sample - loss: 0.2210 - acc: 0.9397 - val_loss: 0.1779 - val_acc: 0.9488\n",
      "Epoch 4/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9479\n",
      "Epoch 00004: val_acc improved from 0.94884 to 0.95866, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1839 - acc: 0.9478 - val_loss: 0.1518 - val_acc: 0.9587\n",
      "Epoch 5/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9567\n",
      "Epoch 00005: val_acc improved from 0.95866 to 0.96163, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1590 - acc: 0.9568 - val_loss: 0.1337 - val_acc: 0.9616\n",
      "Epoch 6/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9605\n",
      "Epoch 00006: val_acc did not improve from 0.96163\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1455 - acc: 0.9605 - val_loss: 0.1504 - val_acc: 0.9596\n",
      "Epoch 7/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9639\n",
      "Epoch 00007: val_acc improved from 0.96163 to 0.96825, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 147us/sample - loss: 0.1369 - acc: 0.9640 - val_loss: 0.1159 - val_acc: 0.9683\n",
      "Epoch 8/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9657\n",
      "Epoch 00008: val_acc did not improve from 0.96825\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1247 - acc: 0.9656 - val_loss: 0.1375 - val_acc: 0.9619\n",
      "Epoch 9/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9675\n",
      "Epoch 00009: val_acc improved from 0.96825 to 0.97442, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1212 - acc: 0.9676 - val_loss: 0.1061 - val_acc: 0.9744\n",
      "Epoch 10/15\n",
      "39168/39399 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9688\n",
      "Epoch 00010: val_acc did not improve from 0.97442\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1141 - acc: 0.9688 - val_loss: 0.1084 - val_acc: 0.9730\n",
      "Epoch 11/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9709\n",
      "Epoch 00011: val_acc did not improve from 0.97442\n",
      "39399/39399 [==============================] - 6s 146us/sample - loss: 0.1065 - acc: 0.9709 - val_loss: 0.1059 - val_acc: 0.9721\n",
      "Epoch 12/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9723\n",
      "Epoch 00012: val_acc did not improve from 0.97442\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "39399/39399 [==============================] - 6s 162us/sample - loss: 0.1044 - acc: 0.9723 - val_loss: 0.1040 - val_acc: 0.9744\n",
      "Epoch 13/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9775\n",
      "Epoch 00013: val_acc improved from 0.97442 to 0.97647, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 148us/sample - loss: 0.0842 - acc: 0.9775 - val_loss: 0.0893 - val_acc: 0.9765\n",
      "Epoch 14/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9789\n",
      "Epoch 00014: val_acc improved from 0.97647 to 0.97693, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 147us/sample - loss: 0.0772 - acc: 0.9789 - val_loss: 0.0869 - val_acc: 0.9769\n",
      "Epoch 15/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9793\n",
      "Epoch 00015: val_acc improved from 0.97693 to 0.97739, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 147us/sample - loss: 0.0734 - acc: 0.9793 - val_loss: 0.0861 - val_acc: 0.9774\n",
      "43777/43777 [==============================] - 2s 41us/sample - loss: 0.0809 - acc: 0.9777\n",
      "43777/43777 [==============================] - 2s 40us/sample - loss: 0.0598 - acc: 0.9833\n",
      "[CV]  dense_size=32, conv3_size=128, conv2_size=32, conv1_size=32, total= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] dense_size=32, conv3_size=128, conv2_size=32, conv1_size=32 .....\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8668\n",
      "Epoch 00001: val_acc improved from -inf to 0.89698, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 9s 237us/sample - loss: 0.4361 - acc: 0.8671 - val_loss: 0.3320 - val_acc: 0.8970\n",
      "Epoch 2/15\n",
      "39200/39399 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9143\n",
      "Epoch 00002: val_acc improved from 0.89698 to 0.92873, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 150us/sample - loss: 0.2934 - acc: 0.9142 - val_loss: 0.2665 - val_acc: 0.9287\n",
      "Epoch 3/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9303\n",
      "Epoch 00003: val_acc improved from 0.92873 to 0.94038, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.2453 - acc: 0.9303 - val_loss: 0.2307 - val_acc: 0.9404\n",
      "Epoch 4/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9404\n",
      "Epoch 00004: val_acc improved from 0.94038 to 0.94769, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.2132 - acc: 0.9403 - val_loss: 0.2090 - val_acc: 0.9477\n",
      "Epoch 5/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1894 - acc: 0.9491\n",
      "Epoch 00005: val_acc improved from 0.94769 to 0.95203, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.1894 - acc: 0.9490 - val_loss: 0.1816 - val_acc: 0.9520\n",
      "Epoch 6/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9536\n",
      "Epoch 00006: val_acc improved from 0.95203 to 0.95637, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 150us/sample - loss: 0.1731 - acc: 0.9536 - val_loss: 0.1617 - val_acc: 0.9564\n",
      "Epoch 7/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9570\n",
      "Epoch 00007: val_acc improved from 0.95637 to 0.96094, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.1577 - acc: 0.9571 - val_loss: 0.1638 - val_acc: 0.9609\n",
      "Epoch 8/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9606\n",
      "Epoch 00008: val_acc improved from 0.96094 to 0.96391, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.1467 - acc: 0.9606 - val_loss: 0.1389 - val_acc: 0.9639\n",
      "Epoch 9/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9634\n",
      "Epoch 00009: val_acc did not improve from 0.96391\n",
      "39399/39399 [==============================] - 6s 148us/sample - loss: 0.1355 - acc: 0.9632 - val_loss: 0.1386 - val_acc: 0.9621\n",
      "Epoch 10/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9650\n",
      "Epoch 00010: val_acc improved from 0.96391 to 0.96825, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.1301 - acc: 0.9649 - val_loss: 0.1294 - val_acc: 0.9683\n",
      "Epoch 11/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9655\n",
      "Epoch 00011: val_acc improved from 0.96825 to 0.96985, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.1256 - acc: 0.9656 - val_loss: 0.1204 - val_acc: 0.9698\n",
      "Epoch 12/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9672\n",
      "Epoch 00012: val_acc did not improve from 0.96985\n",
      "39399/39399 [==============================] - 6s 148us/sample - loss: 0.1199 - acc: 0.9672 - val_loss: 0.1193 - val_acc: 0.9698\n",
      "Epoch 13/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9687\n",
      "Epoch 00013: val_acc improved from 0.96985 to 0.97076, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 149us/sample - loss: 0.1155 - acc: 0.9686 - val_loss: 0.1113 - val_acc: 0.9708\n",
      "Epoch 14/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9691\n",
      "Epoch 00014: val_acc did not improve from 0.97076\n",
      "39399/39399 [==============================] - 6s 148us/sample - loss: 0.1133 - acc: 0.9691 - val_loss: 0.1113 - val_acc: 0.9701\n",
      "Epoch 15/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9698\n",
      "Epoch 00015: val_acc did not improve from 0.97076\n",
      "39399/39399 [==============================] - 6s 148us/sample - loss: 0.1083 - acc: 0.9697 - val_loss: 0.1069 - val_acc: 0.9708\n",
      "43777/43777 [==============================] - 2s 41us/sample - loss: 0.0964 - acc: 0.9735\n",
      "43777/43777 [==============================] - 2s 41us/sample - loss: 0.0843 - acc: 0.9761\n",
      "[CV]  dense_size=32, conv3_size=128, conv2_size=32, conv1_size=32, total= 1.6min\n",
      "[CV] dense_size=16, conv3_size=128, conv2_size=32, conv1_size=16 .....\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8670\n",
      "Epoch 00001: val_acc improved from -inf to 0.92462, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 10s 251us/sample - loss: 0.4428 - acc: 0.8672 - val_loss: 0.2787 - val_acc: 0.9246\n",
      "Epoch 2/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.2692 - acc: 0.9265\n",
      "Epoch 00002: val_acc improved from 0.92462 to 0.93787, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.2693 - acc: 0.9264 - val_loss: 0.2203 - val_acc: 0.9379\n",
      "Epoch 3/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9366\n",
      "Epoch 00003: val_acc improved from 0.93787 to 0.94450, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.2247 - acc: 0.9366 - val_loss: 0.1926 - val_acc: 0.9445\n",
      "Epoch 4/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9467\n",
      "Epoch 00004: val_acc improved from 0.94450 to 0.96300, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 153us/sample - loss: 0.1914 - acc: 0.9467 - val_loss: 0.1535 - val_acc: 0.9630\n",
      "Epoch 5/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9535\n",
      "Epoch 00005: val_acc improved from 0.96300 to 0.96345, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 153us/sample - loss: 0.1710 - acc: 0.9534 - val_loss: 0.1533 - val_acc: 0.9635\n",
      "Epoch 6/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9592\n",
      "Epoch 00006: val_acc improved from 0.96345 to 0.96916, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.1528 - acc: 0.9592 - val_loss: 0.1285 - val_acc: 0.9692\n",
      "Epoch 7/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9629\n",
      "Epoch 00007: val_acc improved from 0.96916 to 0.96985, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.1394 - acc: 0.9628 - val_loss: 0.1209 - val_acc: 0.9698\n",
      "Epoch 8/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9654\n",
      "Epoch 00008: val_acc improved from 0.96985 to 0.97145, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.1295 - acc: 0.9653 - val_loss: 0.1138 - val_acc: 0.9714\n",
      "Epoch 9/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9674\n",
      "Epoch 00009: val_acc improved from 0.97145 to 0.97396, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.1229 - acc: 0.9675 - val_loss: 0.1106 - val_acc: 0.9740\n",
      "Epoch 10/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9692\n",
      "Epoch 00010: val_acc did not improve from 0.97396\n",
      "39399/39399 [==============================] - 6s 151us/sample - loss: 0.1154 - acc: 0.9691 - val_loss: 0.1169 - val_acc: 0.9705\n",
      "Epoch 11/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9693\n",
      "Epoch 00011: val_acc did not improve from 0.97396\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.1088 - acc: 0.9692 - val_loss: 0.1034 - val_acc: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9713\n",
      "Epoch 00012: val_acc improved from 0.97396 to 0.97487, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 151us/sample - loss: 0.1046 - acc: 0.9713 - val_loss: 0.0945 - val_acc: 0.9749\n",
      "Epoch 13/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9731\n",
      "Epoch 00013: val_acc did not improve from 0.97487\n",
      "39399/39399 [==============================] - 6s 151us/sample - loss: 0.1017 - acc: 0.9731 - val_loss: 0.0951 - val_acc: 0.9730\n",
      "Epoch 14/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9740\n",
      "Epoch 00014: val_acc did not improve from 0.97487\n",
      "39399/39399 [==============================] - 6s 151us/sample - loss: 0.0962 - acc: 0.9740 - val_loss: 0.1014 - val_acc: 0.9735\n",
      "Epoch 15/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9743\n",
      "Epoch 00015: val_acc improved from 0.97487 to 0.97579, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 152us/sample - loss: 0.0926 - acc: 0.9742 - val_loss: 0.0914 - val_acc: 0.9758\n",
      "43777/43777 [==============================] - 2s 43us/sample - loss: 0.0895 - acc: 0.9762\n",
      "43777/43777 [==============================] - 2s 43us/sample - loss: 0.0720 - acc: 0.9811\n",
      "[CV]  dense_size=16, conv3_size=128, conv2_size=32, conv1_size=16, total= 1.7min\n",
      "[CV] dense_size=16, conv3_size=128, conv2_size=32, conv1_size=16 .....\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.4603 - acc: 0.8617\n",
      "Epoch 00001: val_acc improved from -inf to 0.91823, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 10s 259us/sample - loss: 0.4586 - acc: 0.8623 - val_loss: 0.3148 - val_acc: 0.9182\n",
      "Epoch 2/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.2827 - acc: 0.9238\n",
      "Epoch 00002: val_acc improved from 0.91823 to 0.92988, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.2830 - acc: 0.9238 - val_loss: 0.2693 - val_acc: 0.9299\n",
      "Epoch 3/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9349\n",
      "Epoch 00003: val_acc improved from 0.92988 to 0.93559, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.2359 - acc: 0.9349 - val_loss: 0.2317 - val_acc: 0.9356\n",
      "Epoch 4/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.2043 - acc: 0.9463\n",
      "Epoch 00004: val_acc improved from 0.93559 to 0.95317, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.2042 - acc: 0.9463 - val_loss: 0.1876 - val_acc: 0.9532\n",
      "Epoch 5/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9519\n",
      "Epoch 00005: val_acc did not improve from 0.95317\n",
      "39399/39399 [==============================] - 6s 153us/sample - loss: 0.1810 - acc: 0.9519 - val_loss: 0.1787 - val_acc: 0.9486\n",
      "Epoch 6/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9551\n",
      "Epoch 00006: val_acc improved from 0.95317 to 0.95889, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.1685 - acc: 0.9552 - val_loss: 0.1539 - val_acc: 0.9589\n",
      "Epoch 7/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9578\n",
      "Epoch 00007: val_acc improved from 0.95889 to 0.95934, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.1570 - acc: 0.9578 - val_loss: 0.1662 - val_acc: 0.9593\n",
      "Epoch 8/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9602\n",
      "Epoch 00008: val_acc improved from 0.95934 to 0.96460, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 155us/sample - loss: 0.1476 - acc: 0.9603 - val_loss: 0.1333 - val_acc: 0.9646\n",
      "Epoch 9/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9619\n",
      "Epoch 00009: val_acc improved from 0.96460 to 0.96962, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.1406 - acc: 0.9618 - val_loss: 0.1186 - val_acc: 0.9696\n",
      "Epoch 10/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9639\n",
      "Epoch 00010: val_acc improved from 0.96962 to 0.97076, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.1324 - acc: 0.9639 - val_loss: 0.1164 - val_acc: 0.9708\n",
      "Epoch 11/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9667\n",
      "Epoch 00011: val_acc improved from 0.97076 to 0.97396, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 155us/sample - loss: 0.1235 - acc: 0.9667 - val_loss: 0.1066 - val_acc: 0.9740\n",
      "Epoch 12/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9668\n",
      "Epoch 00012: val_acc did not improve from 0.97396\n",
      "39399/39399 [==============================] - 6s 153us/sample - loss: 0.1207 - acc: 0.9669 - val_loss: 0.1200 - val_acc: 0.9701\n",
      "Epoch 13/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9680\n",
      "Epoch 00013: val_acc did not improve from 0.97396\n",
      "39399/39399 [==============================] - 6s 153us/sample - loss: 0.1155 - acc: 0.9678 - val_loss: 0.1050 - val_acc: 0.9728\n",
      "Epoch 14/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9691\n",
      "Epoch 00014: val_acc did not improve from 0.97396\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "39399/39399 [==============================] - 7s 177us/sample - loss: 0.1107 - acc: 0.9691 - val_loss: 0.1161 - val_acc: 0.9689\n",
      "Epoch 15/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9742\n",
      "Epoch 00015: val_acc improved from 0.97396 to 0.97556, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 154us/sample - loss: 0.0903 - acc: 0.9742 - val_loss: 0.0928 - val_acc: 0.9756\n",
      "43777/43777 [==============================] - 2s 45us/sample - loss: 0.0806 - acc: 0.9783\n",
      "43777/43777 [==============================] - 2s 45us/sample - loss: 0.0687 - acc: 0.9799\n",
      "[CV]  dense_size=16, conv3_size=128, conv2_size=32, conv1_size=16, total= 1.7min\n",
      "[CV] dense_size=16, conv3_size=256, conv2_size=32, conv1_size=32 .....\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8799\n",
      "Epoch 00001: val_acc improved from -inf to 0.92280, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 11s 274us/sample - loss: 0.4254 - acc: 0.8801 - val_loss: 0.2758 - val_acc: 0.9228\n",
      "Epoch 2/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.9242\n",
      "Epoch 00002: val_acc improved from 0.92280 to 0.92896, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.2719 - acc: 0.9241 - val_loss: 0.2629 - val_acc: 0.9290\n",
      "Epoch 3/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9337\n",
      "Epoch 00003: val_acc improved from 0.92896 to 0.94450, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.2287 - acc: 0.9337 - val_loss: 0.1893 - val_acc: 0.9445\n",
      "Epoch 4/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9450\n",
      "Epoch 00004: val_acc improved from 0.94450 to 0.95363, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 158us/sample - loss: 0.1932 - acc: 0.9450 - val_loss: 0.1621 - val_acc: 0.9536\n",
      "Epoch 5/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9522\n",
      "Epoch 00005: val_acc improved from 0.95363 to 0.96323, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.1715 - acc: 0.9522 - val_loss: 0.1397 - val_acc: 0.9632\n",
      "Epoch 6/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9575\n",
      "Epoch 00006: val_acc improved from 0.96323 to 0.96528, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.1574 - acc: 0.9575 - val_loss: 0.1411 - val_acc: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9619\n",
      "Epoch 00007: val_acc improved from 0.96528 to 0.96871, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.1430 - acc: 0.9620 - val_loss: 0.1291 - val_acc: 0.9687\n",
      "Epoch 8/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9645\n",
      "Epoch 00008: val_acc did not improve from 0.96871\n",
      "39399/39399 [==============================] - 6s 156us/sample - loss: 0.1318 - acc: 0.9644 - val_loss: 0.1241 - val_acc: 0.9667\n",
      "Epoch 9/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9654\n",
      "Epoch 00009: val_acc did not improve from 0.96871\n",
      "39399/39399 [==============================] - 6s 156us/sample - loss: 0.1264 - acc: 0.9655 - val_loss: 0.1161 - val_acc: 0.9683\n",
      "Epoch 10/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9682\n",
      "Epoch 00010: val_acc improved from 0.96871 to 0.96894, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.1197 - acc: 0.9681 - val_loss: 0.1140 - val_acc: 0.9689\n",
      "Epoch 11/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9705\n",
      "Epoch 00011: val_acc improved from 0.96894 to 0.97373, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 157us/sample - loss: 0.1121 - acc: 0.9705 - val_loss: 0.0964 - val_acc: 0.9737\n",
      "Epoch 12/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9704\n",
      "Epoch 00012: val_acc did not improve from 0.97373\n",
      "39399/39399 [==============================] - 6s 156us/sample - loss: 0.1066 - acc: 0.9704 - val_loss: 0.0991 - val_acc: 0.9728\n",
      "Epoch 13/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9727\n",
      "Epoch 00013: val_acc did not improve from 0.97373\n",
      "39399/39399 [==============================] - 6s 155us/sample - loss: 0.1013 - acc: 0.9727 - val_loss: 0.1067 - val_acc: 0.9712\n",
      "Epoch 14/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9737\n",
      "Epoch 00014: val_acc improved from 0.97373 to 0.97396, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 156us/sample - loss: 0.0978 - acc: 0.9737 - val_loss: 0.0967 - val_acc: 0.9740\n",
      "Epoch 15/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9739\n",
      "Epoch 00015: val_acc did not improve from 0.97396\n",
      "39399/39399 [==============================] - 6s 156us/sample - loss: 0.0955 - acc: 0.9740 - val_loss: 0.1004 - val_acc: 0.9719\n",
      "43777/43777 [==============================] - 2s 49us/sample - loss: 0.1010 - acc: 0.9711\n",
      "43777/43777 [==============================] - 2s 48us/sample - loss: 0.0805 - acc: 0.9773\n",
      "[CV]  dense_size=16, conv3_size=256, conv2_size=32, conv1_size=32, total= 1.7min\n",
      "[CV] dense_size=16, conv3_size=256, conv2_size=32, conv1_size=32 .....\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.4510 - acc: 0.8612\n",
      "Epoch 00001: val_acc improved from -inf to 0.90384, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 11s 281us/sample - loss: 0.4502 - acc: 0.8617 - val_loss: 0.3772 - val_acc: 0.9038\n",
      "Epoch 2/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.9176\n",
      "Epoch 00002: val_acc improved from 0.90384 to 0.93307, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 160us/sample - loss: 0.2917 - acc: 0.9175 - val_loss: 0.2404 - val_acc: 0.9331\n",
      "Epoch 3/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9351\n",
      "Epoch 00003: val_acc improved from 0.93307 to 0.95135, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 159us/sample - loss: 0.2232 - acc: 0.9350 - val_loss: 0.1850 - val_acc: 0.9513\n",
      "Epoch 4/15\n",
      "39104/39399 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9495\n",
      "Epoch 00004: val_acc improved from 0.95135 to 0.95546, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 159us/sample - loss: 0.1821 - acc: 0.9496 - val_loss: 0.1830 - val_acc: 0.9555\n",
      "Epoch 5/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9554\n",
      "Epoch 00005: val_acc improved from 0.95546 to 0.96231, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 160us/sample - loss: 0.1634 - acc: 0.9554 - val_loss: 0.1429 - val_acc: 0.9623\n",
      "Epoch 6/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9588\n",
      "Epoch 00006: val_acc improved from 0.96231 to 0.96528, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 159us/sample - loss: 0.1496 - acc: 0.9587 - val_loss: 0.1375 - val_acc: 0.9653\n",
      "Epoch 7/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9617\n",
      "Epoch 00007: val_acc did not improve from 0.96528\n",
      "39399/39399 [==============================] - 6s 159us/sample - loss: 0.1390 - acc: 0.9617 - val_loss: 0.1434 - val_acc: 0.9621\n",
      "Epoch 8/15\n",
      "39136/39399 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9644\n",
      "Epoch 00008: val_acc did not improve from 0.96528\n",
      "39399/39399 [==============================] - 6s 158us/sample - loss: 0.1293 - acc: 0.9643 - val_loss: 0.1356 - val_acc: 0.9621\n",
      "Epoch 9/15\n",
      "39072/39399 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9662\n",
      "Epoch 00009: val_acc improved from 0.96528 to 0.96619, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 159us/sample - loss: 0.1245 - acc: 0.9663 - val_loss: 0.1444 - val_acc: 0.9662\n",
      "Epoch 10/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9678\n",
      "Epoch 00010: val_acc improved from 0.96619 to 0.96734, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 160us/sample - loss: 0.1176 - acc: 0.9677 - val_loss: 0.1302 - val_acc: 0.9673\n",
      "Epoch 11/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9682\n",
      "Epoch 00011: val_acc improved from 0.96734 to 0.96939, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 160us/sample - loss: 0.1128 - acc: 0.9681 - val_loss: 0.1164 - val_acc: 0.9694\n",
      "Epoch 12/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9699\n",
      "Epoch 00012: val_acc improved from 0.96939 to 0.97168, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 161us/sample - loss: 0.1069 - acc: 0.9699 - val_loss: 0.1015 - val_acc: 0.9717\n",
      "Epoch 13/15\n",
      "39296/39399 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9717\n",
      "Epoch 00013: val_acc improved from 0.97168 to 0.97350, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 160us/sample - loss: 0.1024 - acc: 0.9715 - val_loss: 0.0987 - val_acc: 0.9735\n",
      "Epoch 14/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9727\n",
      "Epoch 00014: val_acc did not improve from 0.97350\n",
      "39399/39399 [==============================] - 6s 159us/sample - loss: 0.0999 - acc: 0.9726 - val_loss: 0.0994 - val_acc: 0.9733\n",
      "Epoch 15/15\n",
      "39232/39399 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9739\n",
      "Epoch 00015: val_acc improved from 0.97350 to 0.97465, saving model to CNN_Model.h5\n",
      "39399/39399 [==============================] - 6s 160us/sample - loss: 0.0900 - acc: 0.9739 - val_loss: 0.0883 - val_acc: 0.9746\n",
      "43777/43777 [==============================] - 2s 50us/sample - loss: 0.0799 - acc: 0.9790\n",
      "43777/43777 [==============================] - 2s 53us/sample - loss: 0.0674 - acc: 0.9802\n",
      "[CV]  dense_size=16, conv3_size=256, conv2_size=32, conv1_size=32, total= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 10.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.4084 - acc: 0.8761\n",
      "Epoch 00001: val_acc improved from -inf to 0.92736, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 18s 235us/sample - loss: 0.4084 - acc: 0.8761 - val_loss: 0.2540 - val_acc: 0.9274\n",
      "Epoch 2/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9360\n",
      "Epoch 00002: val_acc improved from 0.92736 to 0.95397, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.2353 - acc: 0.9360 - val_loss: 0.1774 - val_acc: 0.9540\n",
      "Epoch 3/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9483\n",
      "Epoch 00003: val_acc improved from 0.95397 to 0.95694, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1890 - acc: 0.9483 - val_loss: 0.1551 - val_acc: 0.9569\n",
      "Epoch 4/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9546\n",
      "Epoch 00004: val_acc improved from 0.95694 to 0.96380, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1644 - acc: 0.9546 - val_loss: 0.1386 - val_acc: 0.9638\n",
      "Epoch 5/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9598\n",
      "Epoch 00005: val_acc improved from 0.96380 to 0.96562, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1497 - acc: 0.9598 - val_loss: 0.1380 - val_acc: 0.9656\n",
      "Epoch 6/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9629\n",
      "Epoch 00006: val_acc improved from 0.96562 to 0.97213, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1393 - acc: 0.9630 - val_loss: 0.1091 - val_acc: 0.9721\n",
      "Epoch 7/15\n",
      "78656/78798 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9663\n",
      "Epoch 00007: val_acc did not improve from 0.97213\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1293 - acc: 0.9663 - val_loss: 0.1132 - val_acc: 0.9712\n",
      "Epoch 8/15\n",
      "78560/78798 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9683\n",
      "Epoch 00008: val_acc did not improve from 0.97213\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1224 - acc: 0.9683 - val_loss: 0.1199 - val_acc: 0.9708\n",
      "Epoch 9/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9688\n",
      "Epoch 00009: val_acc improved from 0.97213 to 0.97442, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1172 - acc: 0.9688 - val_loss: 0.1003 - val_acc: 0.9744\n",
      "Epoch 10/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9699\n",
      "Epoch 00010: val_acc improved from 0.97442 to 0.97704, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1119 - acc: 0.9699 - val_loss: 0.0908 - val_acc: 0.9770\n",
      "Epoch 11/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9713\n",
      "Epoch 00011: val_acc did not improve from 0.97704\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1066 - acc: 0.9713 - val_loss: 0.0898 - val_acc: 0.9767\n",
      "Epoch 12/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9718\n",
      "Epoch 00012: val_acc improved from 0.97704 to 0.97921, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 13s 167us/sample - loss: 0.1035 - acc: 0.9718 - val_loss: 0.0816 - val_acc: 0.9792\n",
      "Epoch 13/15\n",
      "78656/78798 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9729\n",
      "Epoch 00013: val_acc did not improve from 0.97921\n",
      "78798/78798 [==============================] - 14s 177us/sample - loss: 0.1000 - acc: 0.9729 - val_loss: 0.0914 - val_acc: 0.9756\n",
      "Epoch 14/15\n",
      "78688/78798 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9737\n",
      "Epoch 00014: val_acc did not improve from 0.97921\n",
      "78798/78798 [==============================] - 14s 173us/sample - loss: 0.0953 - acc: 0.9737 - val_loss: 0.0830 - val_acc: 0.9788\n",
      "Epoch 15/15\n",
      "78720/78798 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9744\n",
      "Epoch 00015: val_acc improved from 0.97921 to 0.98001, saving model to CNN_Model.h5\n",
      "78798/78798 [==============================] - 14s 173us/sample - loss: 0.0935 - acc: 0.9744 - val_loss: 0.0770 - val_acc: 0.9800\n",
      "                     Name       ACC\n",
      "0         GaussianMixture  0.451261\n",
      "1  RandomForestClassifier  0.974100\n",
      "2            Residual_CNN  0.827608\n",
      "3               CNN_Model  0.977343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/martin/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 1 is smaller than n_iter=3. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] hidden=64, dense=64 .............................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.4337 - acc: 0.8861\n",
      "Epoch 00001: val_acc improved from -inf to 0.93216, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 17s 439us/sample - loss: 0.4337 - acc: 0.8861 - val_loss: 0.2662 - val_acc: 0.9322\n",
      "Epoch 2/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9415\n",
      "Epoch 00002: val_acc improved from 0.93216 to 0.94861, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 349us/sample - loss: 0.2249 - acc: 0.9415 - val_loss: 0.1940 - val_acc: 0.9486\n",
      "Epoch 3/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9528\n",
      "Epoch 00003: val_acc improved from 0.94861 to 0.95249, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 351us/sample - loss: 0.1726 - acc: 0.9528 - val_loss: 0.1610 - val_acc: 0.9525\n",
      "Epoch 4/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9583\n",
      "Epoch 00004: val_acc improved from 0.95249 to 0.95980, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 351us/sample - loss: 0.1492 - acc: 0.9583 - val_loss: 0.1519 - val_acc: 0.9598\n",
      "Epoch 5/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9617\n",
      "Epoch 00005: val_acc improved from 0.95980 to 0.96094, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 353us/sample - loss: 0.1342 - acc: 0.9616 - val_loss: 0.1365 - val_acc: 0.9609\n",
      "Epoch 6/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9648\n",
      "Epoch 00006: val_acc improved from 0.96094 to 0.96848, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 351us/sample - loss: 0.1213 - acc: 0.9648 - val_loss: 0.1177 - val_acc: 0.9685\n",
      "Epoch 7/15\n",
      "39328/39399 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9682\n",
      "Epoch 00007: val_acc did not improve from 0.96848\n",
      "39399/39399 [==============================] - 14s 351us/sample - loss: 0.1106 - acc: 0.9681 - val_loss: 0.1267 - val_acc: 0.9628\n",
      "Epoch 8/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9705\n",
      "Epoch 00008: val_acc did not improve from 0.96848\n",
      "39399/39399 [==============================] - 14s 349us/sample - loss: 0.1057 - acc: 0.9705 - val_loss: 0.1225 - val_acc: 0.9632\n",
      "Epoch 9/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9718\n",
      "Epoch 00009: val_acc did not improve from 0.96848\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "39399/39399 [==============================] - 15s 384us/sample - loss: 0.0963 - acc: 0.9718 - val_loss: 0.1265 - val_acc: 0.9628\n",
      "Epoch 10/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9788\n",
      "Epoch 00010: val_acc improved from 0.96848 to 0.97579, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 350us/sample - loss: 0.0733 - acc: 0.9788 - val_loss: 0.0885 - val_acc: 0.9758\n",
      "Epoch 11/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9806\n",
      "Epoch 00011: val_acc did not improve from 0.97579\n",
      "39399/39399 [==============================] - 14s 349us/sample - loss: 0.0680 - acc: 0.9806 - val_loss: 0.0889 - val_acc: 0.9751\n",
      "Epoch 12/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9808\n",
      "Epoch 00012: val_acc improved from 0.97579 to 0.97716, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 352us/sample - loss: 0.0661 - acc: 0.9808 - val_loss: 0.0872 - val_acc: 0.9772\n",
      "Epoch 13/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9818\n",
      "Epoch 00013: val_acc did not improve from 0.97716\n",
      "39399/39399 [==============================] - 14s 356us/sample - loss: 0.0640 - acc: 0.9819 - val_loss: 0.0881 - val_acc: 0.9765\n",
      "Epoch 14/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9823\n",
      "Epoch 00014: val_acc did not improve from 0.97716\n",
      "39399/39399 [==============================] - 14s 357us/sample - loss: 0.0625 - acc: 0.9823 - val_loss: 0.0877 - val_acc: 0.9772\n",
      "Epoch 15/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9822\n",
      "Epoch 00015: val_acc did not improve from 0.97716\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "39399/39399 [==============================] - 14s 358us/sample - loss: 0.0614 - acc: 0.9822 - val_loss: 0.0853 - val_acc: 0.9762\n",
      "43777/43777 [==============================] - 7s 159us/sample - loss: 0.0825 - acc: 0.9765\n",
      "43777/43777 [==============================] - 7s 158us/sample - loss: 0.0608 - acc: 0.9834\n",
      "[CV] .............................. hidden=64, dense=64, total= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] hidden=64, dense=64 .............................................\n",
      "Train on 39399 samples, validate on 4378 samples\n",
      "Epoch 1/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.5750 - acc: 0.8463\n",
      "Epoch 00001: val_acc improved from -inf to 0.89470, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 18s 450us/sample - loss: 0.5749 - acc: 0.8463 - val_loss: 0.3903 - val_acc: 0.8947\n",
      "Epoch 2/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9269\n",
      "Epoch 00002: val_acc improved from 0.89470 to 0.92759, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 352us/sample - loss: 0.2909 - acc: 0.9269 - val_loss: 0.2677 - val_acc: 0.9276\n",
      "Epoch 3/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9412\n",
      "Epoch 00003: val_acc improved from 0.92759 to 0.94107, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 353us/sample - loss: 0.2171 - acc: 0.9413 - val_loss: 0.2223 - val_acc: 0.9411\n",
      "Epoch 4/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9485\n",
      "Epoch 00004: val_acc improved from 0.94107 to 0.94975, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 352us/sample - loss: 0.1858 - acc: 0.9486 - val_loss: 0.1903 - val_acc: 0.9497\n",
      "Epoch 5/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9537\n",
      "Epoch 00005: val_acc improved from 0.94975 to 0.95683, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 353us/sample - loss: 0.1623 - acc: 0.9538 - val_loss: 0.1618 - val_acc: 0.9568\n",
      "Epoch 6/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9586\n",
      "Epoch 00006: val_acc did not improve from 0.95683\n",
      "39399/39399 [==============================] - 14s 359us/sample - loss: 0.1407 - acc: 0.9587 - val_loss: 0.1604 - val_acc: 0.9525\n",
      "Epoch 7/15\n",
      "39360/39399 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9611\n",
      "Epoch 00007: val_acc improved from 0.95683 to 0.95866, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 358us/sample - loss: 0.1333 - acc: 0.9611 - val_loss: 0.1321 - val_acc: 0.9587\n",
      "Epoch 8/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9634\n",
      "Epoch 00008: val_acc improved from 0.95866 to 0.95934, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 356us/sample - loss: 0.1213 - acc: 0.9634 - val_loss: 0.1359 - val_acc: 0.9593\n",
      "Epoch 9/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9662\n",
      "Epoch 00009: val_acc did not improve from 0.95934\n",
      "39399/39399 [==============================] - 14s 355us/sample - loss: 0.1116 - acc: 0.9662 - val_loss: 0.1350 - val_acc: 0.9571\n",
      "Epoch 10/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9685\n",
      "Epoch 00010: val_acc improved from 0.95934 to 0.96802, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 354us/sample - loss: 0.1061 - acc: 0.9685 - val_loss: 0.1127 - val_acc: 0.9680\n",
      "Epoch 11/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9694\n",
      "Epoch 00011: val_acc did not improve from 0.96802\n",
      "39399/39399 [==============================] - 14s 354us/sample - loss: 0.1021 - acc: 0.9694 - val_loss: 0.1059 - val_acc: 0.9669\n",
      "Epoch 12/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9715\n",
      "Epoch 00012: val_acc did not improve from 0.96802\n",
      "39399/39399 [==============================] - 14s 354us/sample - loss: 0.0950 - acc: 0.9715 - val_loss: 0.1232 - val_acc: 0.9651\n",
      "Epoch 13/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9711\n",
      "Epoch 00013: val_acc improved from 0.96802 to 0.96871, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 355us/sample - loss: 0.0966 - acc: 0.9711 - val_loss: 0.0974 - val_acc: 0.9687\n",
      "Epoch 14/15\n",
      "39264/39399 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9749\n",
      "Epoch 00014: val_acc improved from 0.96871 to 0.97076, saving model to LSTM_Model.h5\n",
      "39399/39399 [==============================] - 14s 359us/sample - loss: 0.0824 - acc: 0.9749 - val_loss: 0.0949 - val_acc: 0.9708\n",
      "Epoch 15/15\n",
      "39392/39399 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9760\n",
      "Epoch 00015: val_acc did not improve from 0.97076\n",
      "39399/39399 [==============================] - 14s 357us/sample - loss: 0.0794 - acc: 0.9759 - val_loss: 0.0925 - val_acc: 0.9685\n",
      "43777/43777 [==============================] - 7s 162us/sample - loss: 0.0931 - acc: 0.9739\n",
      "43777/43777 [==============================] - 7s 160us/sample - loss: 0.0794 - acc: 0.9751\n",
      "[CV] .............................. hidden=64, dense=64, total= 3.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78798 samples, validate on 8756 samples\n",
      "Epoch 1/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.3397 - acc: 0.9100\n",
      "Epoch 00001: val_acc improved from -inf to 0.94312, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 32s 410us/sample - loss: 0.3396 - acc: 0.9100 - val_loss: 0.2213 - val_acc: 0.9431\n",
      "Epoch 2/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9488\n",
      "Epoch 00002: val_acc improved from 0.94312 to 0.95626, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 28s 358us/sample - loss: 0.1984 - acc: 0.9488 - val_loss: 0.1677 - val_acc: 0.9563\n",
      "Epoch 3/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9583\n",
      "Epoch 00003: val_acc improved from 0.95626 to 0.96574, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 28s 359us/sample - loss: 0.1525 - acc: 0.9583 - val_loss: 0.1225 - val_acc: 0.9657\n",
      "Epoch 4/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9630\n",
      "Epoch 00004: val_acc did not improve from 0.96574\n",
      "78798/78798 [==============================] - 28s 358us/sample - loss: 0.1300 - acc: 0.9630 - val_loss: 0.1253 - val_acc: 0.9630\n",
      "Epoch 5/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9674\n",
      "Epoch 00005: val_acc improved from 0.96574 to 0.97305, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 28s 360us/sample - loss: 0.1154 - acc: 0.9674 - val_loss: 0.0977 - val_acc: 0.9730\n",
      "Epoch 6/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9710\n",
      "Epoch 00006: val_acc improved from 0.97305 to 0.97430, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 28s 360us/sample - loss: 0.1008 - acc: 0.9710 - val_loss: 0.0931 - val_acc: 0.9743\n",
      "Epoch 7/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9727\n",
      "Epoch 00007: val_acc improved from 0.97430 to 0.97487, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 29s 363us/sample - loss: 0.0933 - acc: 0.9727 - val_loss: 0.0848 - val_acc: 0.9749\n",
      "Epoch 8/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9751\n",
      "Epoch 00008: val_acc improved from 0.97487 to 0.97682, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 28s 361us/sample - loss: 0.0856 - acc: 0.9751 - val_loss: 0.0782 - val_acc: 0.9768\n",
      "Epoch 9/15\n",
      "78752/78798 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9767\n",
      "Epoch 00009: val_acc did not improve from 0.97682\n",
      "78798/78798 [==============================] - 29s 364us/sample - loss: 0.0805 - acc: 0.9767 - val_loss: 0.0811 - val_acc: 0.9760\n",
      "Epoch 10/15\n",
      "78688/78798 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9780\n",
      "Epoch 00010: val_acc improved from 0.97682 to 0.97910, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 29s 364us/sample - loss: 0.0747 - acc: 0.9780 - val_loss: 0.0695 - val_acc: 0.9791\n",
      "Epoch 11/15\n",
      "78784/78798 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9792\n",
      "Epoch 00011: val_acc improved from 0.97910 to 0.97956, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 29s 363us/sample - loss: 0.0699 - acc: 0.9792 - val_loss: 0.0726 - val_acc: 0.9796\n",
      "Epoch 12/15\n",
      "78784/78798 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9805\n",
      "Epoch 00012: val_acc improved from 0.97956 to 0.98047, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 31s 389us/sample - loss: 0.0653 - acc: 0.9805 - val_loss: 0.0668 - val_acc: 0.9805\n",
      "Epoch 13/15\n",
      "78688/78798 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9814\n",
      "Epoch 00013: val_acc did not improve from 0.98047\n",
      "78798/78798 [==============================] - 32s 408us/sample - loss: 0.0631 - acc: 0.9814 - val_loss: 0.0652 - val_acc: 0.9804\n",
      "Epoch 14/15\n",
      "78656/78798 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9816\n",
      "Epoch 00014: val_acc did not improve from 0.98047\n",
      "78798/78798 [==============================] - 31s 397us/sample - loss: 0.0617 - acc: 0.9816 - val_loss: 0.0691 - val_acc: 0.9793\n",
      "Epoch 15/15\n",
      "78720/78798 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9827\n",
      "Epoch 00015: val_acc improved from 0.98047 to 0.98253, saving model to LSTM_Model.h5\n",
      "78798/78798 [==============================] - 31s 397us/sample - loss: 0.0586 - acc: 0.9827 - val_loss: 0.0584 - val_acc: 0.9825\n",
      "                     Name       ACC\n",
      "0         GaussianMixture  0.451261\n",
      "1  RandomForestClassifier  0.974100\n",
      "2            Residual_CNN  0.827608\n",
      "3               CNN_Model  0.977343\n",
      "4              LSTM_Model  0.980084\n"
     ]
    }
   ],
   "source": [
    "model_preds = []\n",
    "for param, model in zip(params, models_):\n",
    "    clf = RandomizedSearchCV(model, param, cv=2,n_iter=3, verbose=2)\n",
    "    if type(model) == RandomForestClassifier or \\\n",
    "        type(model) == sklearn.mixture.GaussianMixture or \\\n",
    "        type(model) == sklearn.mixture.BayesianGaussianMixture:\n",
    "        clf.fit(np.squeeze(X), np.argmax(Y,axis=-1))\n",
    "        model = clf.best_estimator_\n",
    "        model.getScores = types.MethodType(models.CNN_Model.getScores_multi, model)\n",
    "        _, metrics_df = model.getScores(np.squeeze(X_test), Y_test, metrics_df)\n",
    "    else:\n",
    "        clf.fit(X, Y)\n",
    "        model = clf.best_estimator_\n",
    "        pred, metrics_df = model.getScores_multi(X_test, Y_test, metrics_df)\n",
    "        model_preds.append(pred)\n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = np.array(model_preds)\n",
    "model_preds = np.squeeze(model_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pred = np.mean(model_preds,axis=0)\n",
    "metrics_df = getScores('Ensemble(Avg)',Y_test=Y_test,pred_test=avg_pred,metrics_df=metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg = LogisticRegression(n_jobs=-1,multi_class = 'multinomial',solver='lbfgs')\n",
    "X_lg = np.transpose(model_preds,[1,2,0])\n",
    "n_samples = X_lg.shape[0]\n",
    "X_lg = np.reshape(X_lg,[n_samples,-1])\n",
    "lg.fit(X_lg,np.argmax(Y_test,axis=-1))\n",
    "lg_pred = lg.predict_proba(X_lg)\n",
    "metrics_df = getScores('Ensemble(LG)',Y_test=Y_test,pred_test=lg_pred,metrics_df=metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Name       ACC\n",
      "0         GaussianMixture  0.451261\n",
      "1  RandomForestClassifier  0.974100\n",
      "2            Residual_CNN  0.827608\n",
      "3               CNN_Model  0.977343\n",
      "4              LSTM_Model  0.980084\n",
      "5           Ensemble(Avg)  0.976567\n",
      "6            Ensemble(LG)  0.982414\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
